{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/aokdata/Land_Cover_Classification/blob/main/Land_Cover_Classification_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlEd9QBXAzFi"
   },
   "source": [
    "# Land Cover Classification of RGB Satellite Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--POcu7uAzFo"
   },
   "source": [
    "**Aidan O'Keefe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Dt2o_92AzFo"
   },
   "source": [
    "![LandCoverClasses.png](attachment:LandCoverClasses.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_F5ia0JAzFp"
   },
   "source": [
    "*Samples of each of the Land Cover Classes; from top left- Annual Crop, Forest, Herbaceous Vegetation, Highway, Industrial, Pasture, Permanent Crop, Residential, River, Sea or Lake*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7h36X1GAzFq"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbZu3cpDAzFq"
   },
   "source": [
    "A deep learning (neural network) land cover classification project using RGB satellite images (remote sensing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzPv2DOfAzFr"
   },
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBhgPaeLAzFs"
   },
   "source": [
    "The Nature Conservancy (TNC) is looking to help protect wildlife migration corridors from development/deforestation, but they canâ€™t be everywhere at once. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUK2l9jpAzFs"
   },
   "source": [
    "In order to help them find where to focus their efforts, we want to build Land Cover Classifier so that TNC can monitor deforestation using satellite images to observe if land starts changing from forest or vegetation to another class.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4W8NxqCAzFt"
   },
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMNBPbyVAzFt"
   },
   "source": [
    "For this project, I am using RGB satellite images from [EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification](https://zenodo.org/record/7711810#.ZCtEhOzMJQK)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rf7DI1OdAzFt"
   },
   "source": [
    "This dataset contains 27,000 RGB Satellite Images across 10 classes: \n",
    "- Annual Crop\n",
    "- Forest\n",
    "- Herbaceous Vegetation\n",
    "- Highway\n",
    "- Industrial\n",
    "- Pasture\n",
    "- Permanent Crop\n",
    "- Residential\n",
    "- River\n",
    "- Sea or Lake <br><br>\n",
    "\n",
    "There are about 2,500 images per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eVs2TRVkAzFu"
   },
   "outputs": [],
   "source": [
    "#Import needed libraries\n",
    "import os, shutil\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "#Standard Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualizations\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "from keras import models, layers, optimizers, regularizers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.data.experimental import cardinality\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense # creates densely connected layer object\n",
    "from tensorflow.keras.layers import Flatten # takes 2D input and turns into 1D array\n",
    "from tensorflow.keras.layers import Conv2D # convolution layer\n",
    "from tensorflow.keras.layers import MaxPooling2D # max pooling layer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "#Transfer Learning\n",
    "from keras.applications import ResNet50, VGG19, VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aim-QQSxAzFv"
   },
   "source": [
    "### Import Data and Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVWgCGlwAzFv"
   },
   "outputs": [],
   "source": [
    "#Split Images into Train and Test folders using OS and Shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "keitW2mkAzFw"
   },
   "outputs": [],
   "source": [
    "#List image path for all categories\n",
    "data_AnnualCrop = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/AnnualCrop'\n",
    "data_Forest = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/Forest'\n",
    "data_HerbaceousVegetation = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/HerbaceousVegetation'\n",
    "data_Highway = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/Highway'\n",
    "data_Industrial = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/Industrial'\n",
    "data_Pasture = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/Pasture'\n",
    "data_PermanentCrop = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/PermanentCrop'\n",
    "data_Residential = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/Residential'\n",
    "data_River = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/River'\n",
    "data_SeaLake = '/Users/Aidan/Documents/Flatiron/Phase_5/EuroSAT_RGB/SeaLake'\n",
    "\n",
    "\n",
    "new_dir = 'data/split/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKC0YUHUAzFw"
   },
   "outputs": [],
   "source": [
    "#Create objects that store all the relevant image names.\n",
    "imgs_AnnualCrop = [file for file in os.listdir(data_AnnualCrop) if file.endswith('.jpg')]\n",
    "imgs_Forest = [file for file in os.listdir(data_Forest) if file.endswith('.jpg')]\n",
    "imgs_HerbaceousVegetation = [file for file in os.listdir(data_HerbaceousVegetation) if file.endswith('.jpg')]\n",
    "imgs_Highway = [file for file in os.listdir(data_Highway) if file.endswith('.jpg')]\n",
    "imgs_Industrial = [file for file in os.listdir(data_Industrial) if file.endswith('.jpg')]\n",
    "imgs_Pasture = [file for file in os.listdir(data_Pasture) if file.endswith('.jpg')]\n",
    "imgs_PermanentCrop = [file for file in os.listdir(data_PermanentCrop) if file.endswith('.jpg')]\n",
    "imgs_Residential = [file for file in os.listdir(data_Residential) if file.endswith('.jpg')]\n",
    "imgs_River = [file for file in os.listdir(data_River) if file.endswith('.jpg')]\n",
    "imgs_SeaLake = [file for file in os.listdir(data_SeaLake) if file.endswith('.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9-GjhahAzFw"
   },
   "outputs": [],
   "source": [
    "# Make new split folder\n",
    "os.mkdir(new_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oEi_iIG_AzFx"
   },
   "outputs": [],
   "source": [
    "#Set up the Train folder and subfolders\n",
    "train_folder = os.path.join(new_dir, 'train')\n",
    "train_AnnualCrop = os.path.join(train_folder, 'AnnualCrop')\n",
    "train_Forest = os.path.join(train_folder, 'Forest')\n",
    "train_HerbaceousVegetation = os.path.join(train_folder, 'HerbaceousVegetation')\n",
    "train_Highway = os.path.join(train_folder, 'Highway')\n",
    "train_Industrial = os.path.join(train_folder, 'Industrial')\n",
    "train_Pasture = os.path.join(train_folder, 'Pasture')\n",
    "train_PermanentCrop = os.path.join(train_folder, 'PermanentCrop')\n",
    "train_Residential = os.path.join(train_folder, 'Residential')\n",
    "train_River = os.path.join(train_folder, 'River')\n",
    "train_SeaLake = os.path.join(train_folder, 'SeaLake')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DEfz7j5AzFx"
   },
   "outputs": [],
   "source": [
    "#Set up the Test folder and subfolders\n",
    "test_folder = os.path.join(new_dir, 'test')\n",
    "test_AnnualCrop = os.path.join(test_folder, 'AnnualCrop')\n",
    "test_Forest = os.path.join(test_folder, 'Forest')\n",
    "test_HerbaceousVegetation = os.path.join(test_folder, 'HerbaceousVegetation')\n",
    "test_Highway = os.path.join(test_folder, 'Highway')\n",
    "test_Industrial = os.path.join(test_folder, 'Industrial')\n",
    "test_Pasture = os.path.join(test_folder, 'Pasture')\n",
    "test_PermanentCrop = os.path.join(test_folder, 'PermanentCrop')\n",
    "test_Residential = os.path.join(test_folder, 'Residential')\n",
    "test_River = os.path.join(test_folder, 'River')\n",
    "test_SeaLake = os.path.join(test_folder, 'SeaLake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NUak31sAzFx"
   },
   "outputs": [],
   "source": [
    "# Make the Train directories(folders)\n",
    "os.mkdir(train_folder)\n",
    "os.mkdir(train_AnnualCrop)\n",
    "os.mkdir(train_Forest)\n",
    "os.mkdir(train_HerbaceousVegetation)\n",
    "os.mkdir(train_Highway)\n",
    "os.mkdir(train_Industrial)\n",
    "os.mkdir(train_Pasture)\n",
    "os.mkdir(train_PermanentCrop)\n",
    "os.mkdir(train_Residential)\n",
    "os.mkdir(train_River)\n",
    "os.mkdir(train_SeaLake)\n",
    "\n",
    "# Make the Test directories(folders)\n",
    "os.mkdir(test_folder)\n",
    "os.mkdir(test_AnnualCrop)\n",
    "os.mkdir(test_Forest)\n",
    "os.mkdir(test_HerbaceousVegetation)\n",
    "os.mkdir(test_Highway)\n",
    "os.mkdir(test_Industrial)\n",
    "os.mkdir(test_Pasture)\n",
    "os.mkdir(test_PermanentCrop)\n",
    "os.mkdir(test_Residential)\n",
    "os.mkdir(test_River)\n",
    "os.mkdir(test_SeaLake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDoSqY4OAzFy"
   },
   "outputs": [],
   "source": [
    "# Compile 80% of images into folders- Train\n",
    "imgs = imgs_AnnualCrop[:2400]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_AnnualCrop, img)\n",
    "    destination = os.path.join(train_AnnualCrop, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Forest[:2400]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Forest, img)\n",
    "    destination = os.path.join(train_Forest, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "\n",
    "imgs = imgs_HerbaceousVegetation[:2400]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_HerbaceousVegetation, img)\n",
    "    destination = os.path.join(train_HerbaceousVegetation, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Highway[:2000]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Highway, img)\n",
    "    destination = os.path.join(train_Highway, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Industrial[:2000]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Industrial, img)\n",
    "    destination = os.path.join(train_Industrial, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Pasture[:1600]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Pasture, img)\n",
    "    destination = os.path.join(train_Pasture, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_PermanentCrop[:2000]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_PermanentCrop, img)\n",
    "    destination = os.path.join(train_PermanentCrop, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Residential[:2400]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Residential, img)\n",
    "    destination = os.path.join(train_Residential, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_River[:2000]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_River, img)\n",
    "    destination = os.path.join(train_River, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_SeaLake[:2400]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_SeaLake, img)\n",
    "    destination = os.path.join(train_SeaLake, img)\n",
    "    shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tJmAqS4AzFy"
   },
   "outputs": [],
   "source": [
    "# Compile other 20% of images into folders- Test\n",
    "imgs = imgs_AnnualCrop[2400:] #600\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_AnnualCrop, img)\n",
    "    destination = os.path.join(test_AnnualCrop, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Forest[2400:] #600\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Forest, img)\n",
    "    destination = os.path.join(test_Forest, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "\n",
    "imgs = imgs_HerbaceousVegetation[2400:] #600\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_HerbaceousVegetation, img)\n",
    "    destination = os.path.join(test_HerbaceousVegetation, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Highway[2000:] #500\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Highway, img)\n",
    "    destination = os.path.join(test_Highway, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Industrial[2000:] #500\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Industrial, img)\n",
    "    destination = os.path.join(test_Industrial, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Pasture[1600:] #400\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Pasture, img)\n",
    "    destination = os.path.join(test_Pasture, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_PermanentCrop[2000:] #500\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_PermanentCrop, img)\n",
    "    destination = os.path.join(test_PermanentCrop, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_Residential[2400:] #600\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_Residential, img)\n",
    "    destination = os.path.join(test_Residential, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_River[2000:] #500\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_River, img)\n",
    "    destination = os.path.join(test_River, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "imgs = imgs_SeaLake[2400:] #600\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_SeaLake, img)\n",
    "    destination = os.path.join(test_SeaLake, img)\n",
    "    shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kOkLuiV7AzF0",
    "outputId": "91bf55af-457f-4448-9fd2-a512fa3d037e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18900 images belonging to 10 classes.\n",
      "Found 2700 images belonging to 10 classes.\n",
      "Found 5400 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_folder = 'data/split/train'\n",
    "test_folder = 'data/split/test'\n",
    "\n",
    "# Normalize images\n",
    "train_gen = ImageDataGenerator(rescale=1./255, validation_split = 0.125)\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#Import data as 70% Train (10% Validation of orginal data set) and 20% Test\n",
    "train_generator = train_gen.flow_from_directory(train_folder,\n",
    "                                                class_mode = 'categorical', \n",
    "                                                subset ='training', \n",
    "                                                batch_size=128,\n",
    "                                                shuffle=True,\n",
    "                                                seed=42)\n",
    "                                               \n",
    "val_generator= train_gen.flow_from_directory(train_folder,\n",
    "                                             class_mode= 'categorical',\n",
    "                                             subset = \"validation\",\n",
    "                                             batch_size=128,\n",
    "                                             shuffle=True,\n",
    "                                             seed=42)\n",
    "\n",
    "test_generator= test_gen.flow_from_directory(test_folder,\n",
    "                                              class_mode= 'categorical',\n",
    "                                              batch_size=128,\n",
    "                                              shuffle=False,\n",
    "                                              seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uyAGupOSAzF1"
   },
   "outputs": [],
   "source": [
    "# create the data sets\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApQ1qbmuAzF1"
   },
   "source": [
    "### Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_xM--0hAzF1",
    "outputId": "2f2ec8f0-8739-4715-b813-5fe0ebd9748d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ~ [(0, 2100), (1, 2100), (2, 2100), (3, 1750), (4, 1750), (5, 1400), (6, 1750), (7, 2100), (8, 1750), (9, 2100)]\n",
      "Validation ~ [(0, 300), (1, 300), (2, 300), (3, 250), (4, 250), (5, 200), (6, 250), (7, 300), (8, 250), (9, 300)]\n",
      "Test ~ [(0, 600), (1, 600), (2, 600), (3, 500), (4, 500), (5, 400), (6, 500), (7, 600), (8, 500), (9, 600)]\n"
     ]
    }
   ],
   "source": [
    "#Confirm class balance for train and test\n",
    "train_classes = train_generator.classes\n",
    "val_classes = val_generator.classes\n",
    "test_classes = test_generator.classes\n",
    "\n",
    "#Look at image distribution by class across train, test, and validation sets.\n",
    "train_class, train_count = np.unique(train_classes, return_counts=True)\n",
    "val_class, val_count = np.unique(val_classes, return_counts=True)\n",
    "test_class, test_count = np.unique(test_classes, return_counts=True)\n",
    "\n",
    "print('Train ~ {}'.format(list(zip(train_class, train_count))))\n",
    "print('Validation ~ {}'.format(list(zip(val_class, val_count))))\n",
    "print('Test ~ {}'.format(list(zip(test_class, test_count))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zF7KS8FIAzF2",
    "outputId": "25fd9b87-d1a8-43e5-86c8-5f224b856d09",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'AnnualCrop': 0, 'Forest': 1, 'HerbaceousVegetation': 2, 'Highway': 3, 'Industrial': 4, 'Pasture': 5, 'PermanentCrop': 6, 'Residential': 7, 'River': 8, 'SeaLake': 9}\n",
      "Validation: {'AnnualCrop': 0, 'Forest': 1, 'HerbaceousVegetation': 2, 'Highway': 3, 'Industrial': 4, 'Pasture': 5, 'PermanentCrop': 6, 'Residential': 7, 'River': 8, 'SeaLake': 9}\n",
      "Train: {'AnnualCrop': 0, 'Forest': 1, 'HerbaceousVegetation': 2, 'Highway': 3, 'Industrial': 4, 'Pasture': 5, 'PermanentCrop': 6, 'Residential': 7, 'River': 8, 'SeaLake': 9}\n"
     ]
    }
   ],
   "source": [
    "#Checking the classes in our train data \n",
    "train_class_names = train_generator.class_indices\n",
    "print('Train:', train_class_names)\n",
    "\n",
    "#Checking the classes in our validation data\n",
    "val_class_names = val_generator.class_indices\n",
    "print('Validation:', val_class_names)\n",
    "\n",
    "#Checking the classes in our test data\n",
    "test_class_names = test_generator.class_indices\n",
    "print('Train:', test_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dukgFJwrAzF2",
    "outputId": "ed55f809-bdef-410e-c3cc-25a159186d18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "(128, 256, 256, 3)\n",
      "(128, 10)\n",
      "Validation\n",
      "(128, 256, 256, 3)\n",
      "(128, 10)\n",
      "Test\n",
      "(128, 256, 256, 3)\n",
      "(128, 10)\n"
     ]
    }
   ],
   "source": [
    "# Preview the shape of both the images and labels for both the train, validation, and test sets (8 objects total)\n",
    "print(\"Train\")\n",
    "print(np.shape(train_images))\n",
    "print(np.shape(train_labels))\n",
    "print(\"Validation\")\n",
    "print(np.shape(val_images))\n",
    "print(np.shape(val_labels))\n",
    "print(\"Test\")\n",
    "print(np.shape(test_images))\n",
    "print(np.shape(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lwc91RwOAzF2",
    "outputId": "6e7cba57-4d1c-41fe-c611-b7dc608b55c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAIAAADTED8xAAAe00lEQVR4nO2dzaokSXKFXR4R5K2iQTQSA6KZnZYC7QR6Hb2Z3kJ6Cm2EQAs1M4hGmxmaEU3VTTzD0Wa4/p1qOwrPqp7FlNtZRUV5eHhEpt+0n2PH/uLdP/1zuUI/+9vxcYzzRz3fjl/v93F+ez+ureOC1sf4Wjfc4PXtcKvjXqUc4fHZcPb2Go7pfcx/4r6ljIs3rKHWG67lGgbOHt/LAwvl+BPPflTct+H0WIOuH8+Iz6VuFWP4jC9mnus18/24NRwF72of7/CO70ORtQ1UvIeN5/nVqGM9XAOfSzHG1xo/L78b8coSiUWQGyCxNHIDJJbGTmvX7gbYcGenjTVsQdpwHROdsOHkPwS0pzlT+3TgH4cYm7hvPx/7CWg30450dr9dg7PvBTN+Aux4Gr/yHmIfpm7X952z+6+h/gbO8yPlO8R/cLz4FXwuWeb15+jBd2J8j3o1IpFYBLkBEksjN0Biaex1j23fzTgHW6fdjCG8gEaWOAexbbeJ3cb4N/fndUyXcLZv3W7hmK0634Nxcc5fcd7ZrIxhM96PtfG1ybVxDuTYcWmPcyanc1uI7do3aA15iWPkdpjPkUU/kOfB8uk/2NzFMd6hfiPhZ2LSiu9Ye4x1vtzG97PJe4hfSv4CJJZGboDE0sgNkFgau9i4PY4rby5ELjPFe+k8efGw8w7YcL043ksca+/nzIJwV8tpKeY8fQPzTsx58k/ag3MiLl5djJ9nY06OpivMczmX5HwuT/Ltt9++Hf/0gfkcHPaPb8e1wEHB51UNF+hLQP+H76e12H9zyF+AxNLIDZBYGrkBEktjn7HvNeYd21UbxjQYiZvhw2wb7drBHddYO6+IOTAuBq/cfRNjtnx6xNSNQS1n27C/+0F+PPjuzFeQAkNO/BFz3+VuPfYlzsKaClPngBqDivX0E9ei4ONX3/3N2/GH7394Oz66SRKJr2X8N15p8yeEs+MdD8q9wwHJRUysIJH4apEbILE0cgMklsbubCnPdYmdhlZiXopDax/k6nh1sPVNjoLw3J4YLj6tnPXrex30Z8z7cePJiffcfbyfSns6rm2wUPI+jmMu1vff/9dYWzM5nO44S8P3aFIngM/ILFM5SPEY91kLf4xpCfKUwAfLX4DE0sgNkFgauQESS2M/TZ2u41ccN/DpC+L3Pa5D9TwcjsFZIZLHc5IT3x7h8n0tgdQoX+cTist7mNi28NdNuFysb3n90FN6skaZz3vAd5J5jAsgFCHOY1wSztncexY7nu855oYR6ps5nhhfKL9A0ZWlHDX+LuUvQGJp5AZILI3cAImlMaULRBvudHWoEzx7l08g52cTHg7OCyeeXHmzBhq2qH89CuLlrGGQ52KNBKbE/PRVyIMqdcZ2v85p8J2/3snz4SzgBTEnwCXEUj02JaCfkcsbYESN8wNNODmvJYIvE2BuxI3BaGo9cVIzv3ClrqdPJL5e5AZILI3cAImlsR/WZr3mwVMf5pjidg9UxvhJdXnn7HKCNjTizeCfyJVum0/MX8lrt7kCYx/jWk234HynrTyO2yN+Rtr6H6jBf757OzxQV1AOF0cnYj/K9kOQXA3WPOHvzcDmMQSsr4h1ivTTSl2gROJnyA2QWBq5ARJLY5+JT1fhf6Nf2JN2v3IwUAt7m6nvjOsTThfQntjaziaWnIPR/yE/itwVcl1cOwTJjex8/385zgsn53/fjr/71dDq+e7Xf/92/B///Ye349/9AXO2H8c8O2qXWaNMTr/4M8PHoNwr+f3OXq+mZoC6Sd6+d3i2JuS6NiN/ARJLIzdAYmnkBkgsjd3/F2PV1xOdtM8mbOs7+eLsJQyt9yJa+PGxdMcVu9ytYXCBDpPrEHlJmQdr5gWIQ58TejWlxEUM3XCibiga+Lu//atx/I//8Hb87jfj2n/7d/zjw/+M+T8MbZ8TKYSPr1jzRrsfdb3C7wefCs/ufEWpAsGjH6L3OnIOnVccrp4EUJGm8D9cj+H8BUgsjdwAiaWRGyCxNP4fHwB2OTR8qNNCTnx/uNgqbbJhF95QWyx2/wyHpNFG5KWMx8eXCr/lxMUH7zvRW3cbxuyJ1ygcGMTyXW1DKXi3RYLt43i8qvKbH4Yd/8O//ss4fh06nr//Eb7Q/ae34/dSvgv7eDO6TMb5a3dyhFibQdvafX/wneHnKP0EqLPE+eP+cXO8I/qorKNIJBZGboDE0sgNkFgan+gCxRovtK1Pcl2EU+G4OrF9Sbtfen45zX6eF35OrIvvue+YErZvb+a+7lrjPkm8Ge+EnBmtOf5mnKV+P3j8H2C//udvh03fym/HfeuPOD/0hQ74GD/N8PIhBtSdmJGAOQ28T5yV7w99sM1wz/b4vlYXaALqm33uLInEV4bcAImlkRsgsTT2fpoYKvnotxHfPR/DhpvZPQ3indttRgsyho6BnUpSCwPmE9xx7TvmfJg4Vu16FR9H/D61ZzBGUKNGaojjOo1W/xoXw98AV2crv3s75sc7w1MyLpvUDEgFxilMn7GGanweqw0FTSH4h6zzZn2CehmuPoQPE+eI8hcgsTRyAySWRm6AxNLYrf1ty31n+n/R5mMM+Hq/zcTyOUa1Qc2cQhi61qfXXgTj2vsj9hn02lgHU/oGyDscdq2+HmqkcjwNWKdJGvfk8vXfsQ6SyO5bn2fkHE5zL9/LOY7rS2+KB3vJDajv6j6XiXrucEQisQhyAySWRm6AxNLYGSgm91p4/z22HZ29zmubiysbODuyMwZvOEgES3mV7x73xHUuD+1+B8d9og19Y+3EnfWyjG0Pfc9N3jPj5XwnqLFmDTF9A3CB+E6Ec29pUy0+3tgDmFr71/0ECNYPyOfeyBe6nEbtfukjca1dm78AiaWRGyCxNHIDJJbG3m7g/HT0AKatKQWt41Di/eTSNNRcUneSNaaH42yAX07NGXLHpf/XR1y7h0MEhuwij4h/yDTk+Uh+A74EcxRyB+icYp5WRz3ABr7QARtaex3ENvfB5xJpHOQThBeEOorDcWnGtQfnQU7gfhvzvOeYO3MpI1fQ4P/wRcszmjoBgpwr6VMhD296jZ18h4nEwsgNkFgauQESS2PfTJzb8d0J2v1GckZsO8kVFMPZQG3ucSDeLDcG7/x0dv9zCQjJM2Aexo9PvSAEbehDyoZju/bosa3fyK03wfDuyPtTbRvIoYp588QpeYBxeCOnX74zRu/VrY29fqUv9XX/aQflINF/Cw8TifWQGyCxNHIDJJbGXl3/VMRi6Q8chv/jeEEV9lzDfnMa/1s1dr/FdZ3rTI1B3WO9o7OQW8IroOHj8iTSBiDm8NQS81W0X69Zc3j2czBTPx1D63efnYc8/li7k9pKp/uu4tjVnKjEVPYISyRKKbkBEosjN0BiaezaSzWur1Vtx9juJ6SmE+NvUss7xou9+1zr4dK22J52cW5bn4rjWl7CMdXQl5gPOSd6CxzlufEzmPFzRK+T10rtRDz/zLXymU74YHoe1/ri7ufAHgiiJQX/7ckpE4mvCrkBEksjN0BiaXwics861HHW8y7AcTc9m2xsG7Nsjm/jwHnwBBUkHjUXr43HbaoXMsDyBHL3hcsUc1oknq0k/bEeWVwcX6etPONLuL92M36Xq/atG2tIRn2z6kHFfZHV1McdbI9nfpeovxS/H+ebsYd0/gIklkZugMTSyA2QWBq75YEIpyLW6rE2HK9k3Hci3jwDyTPIefaWmjDqgZn8xgzIfWLiQJQsUUvtam21a/GX8P6fxQwDy3F+6FJSd+haU9Xrlg74z4j944ZPcn84DltqgyYSpZTcAInFkRsgsTR22ky9m/rOKVtTrPFwhLP7Z+oKuqkZfTEcfQcXLZ/SsMeYj7QjYevfpF9VrNPvezLEeRJvl38+j1+1lZ7jI7m/mvoO0XNgogfcszXc7jvTxPc7cR4rE22lRGJh5AZILI3cAImlsTNWKmF09gqQbeIcAsPHmLCtbV0BuTGw+6ssNO5vIPdiz11olfYJbRnHg39XzTy7sWXJlSJPfbu2ffl++Ozis7l+xnKWfcdif0k1+6/5NtRyFbexkldm+kjsfIdxjzNf48uaDbxDfNYNxdr0zfjo+QuQWBq5ARJLIzdAYmnsd8RKb1IHHIvdnGbL9Dv5LeCIwzDsmNP1bCqNejjkxpjesbAFlT9TcH6s5xU10DM1AA6dfB7y/qmDuT9H1hH9Jc4p9mvsM2xn3AeAb6WJj8S62Ljmu0vRA8ejb8Bt8H+og9Ta+IyYB9AewKwbpo/B8/GHZHloGC990PC92lDznb8AiaWRGyCxNHIDJJbGfsM/DsOxFruwx/FgXlp5ram/dHkAakQ29NB11nQ72BvL8cjjwG81/bxmtOdn+C30MTjj6bg3iHmfQq0iR2iibkF4PuOQzzvj/rjeCOT3f/g4DP8DDRH0/bAmOM6s+NoSlydBPoT+CUoSDr5E+hiPuK9FIrEccgMklkZugMTS2I96zcHo2CfV2Z2wm5upIXZxZdVwZByX9xVFSszO+XHfBr8CMfVjwvidqgme0OJk7S/1c+yUX1CLLA9muS7kFLHvAf001nzH+p4dHJujv3tqmaoR5Hg+sS/6yaj4LPlR4oawriO1QROJUkpugMTiyA2QWBqiDSrca9jlsktEesdpLF73cvpETB7njf/A5r192NOHBqjD+R1HqJg6gRn4Z8f0hgMjmkuwR8+J0twv0Swif6lKfQWTBbC5H/GCDD2nbMVoHB1O0xPX2pqH+F4z2Dr5VPH3Kn8BEksjN0BiaeQGSCyNXfn95MbEdqqCcWLWaG7hGK0Zjfs3kf8tqQJyh8DvL+Tfl9jmftbub8ZWlmnCs4oZe13WNqHPM8NTcqsTfo6bh0OkKUBcc6z1uNc94Fx9MH0D2yKsxr3b5sD8Q+oCJRKllNwAicWRGyCxNHZQZpQnQ76E2GSw6XHW26bXfQMcTLj8kzpjG+V/w4ZkwWlqBgitx8U8l3dS6DNSFyg8LXC9FLrR5/mSv2Sao4g1WM87LqDb9Y6+Fv4DOQTRda3X+lHaa4wcquseAtY/QcqLeYb8BUgsjdwAiaWRGyCxNHZyaTaJ2ce6+AITR3exXod+xnWi1Kshz4QG8n0f8ePKnlAcz9C/+DNxj14ZsV3nQ/R5+T+sV2ZPX3L3zd8g8GcO2Kz3Dr0dfi6P2Md4thebxOyxfNrukjsiR6vG9QPu+6A6pPwAdjPefK/s/CUEeWX5C5BYGrkBEksjN0BiaeyM19YS82dY43siccAQvKslLYa/sclxXCusPBlMKVUMH8cQE2NmbJi9Ds4ihJUxj9Qis/5YxFPDO0lMPaYpCRo1bYzR2idI8b3GMXJHL6JvIJr9hsfFR28yAv3RehyD17i+eUbyc7C47YhrS4QzJj2JXUeHWP80fwESSyM3QGJp5AZILI2dsdhmuCsMf1cbO4cdxj4AM/1fK/VAYZ8Jpz+uE/imfzvui6Ja6S0AOomaxJjoFnOc2iP2B1x4nbz2Dp1TUTWSEPY1V4p+xQFt+xP+28F32OIYeZda2Pi+tOlLex8u+mCOwvQcIJTPo3cL1zORu3DxfuEvmfpjIn8BEksjN0BiaeQGSCyNvRmujtsZ1OJ8oXHN3lvMJxh9ScaqJQ7t+grj+G6JOzye0O9nTBrjT1eUatajGkGx3S/XfgE/x9VhS2wb4fhjH6ugP+MgKZzDvGeBqU+Afqj2ApvIn+iKJsY/y0m7/owSiSWQGyCxNHIDJJbG3rAFWBMsXAsJ0cJWFrs/BmtYldIS8zGYc7ifsT6PxONhx7/eB+eE/snZ+GDMFYglj0Pea5xu5s/FUeL8gOWy864TvJSOglzmDaR3m+EUdeHhcG1GO8jQqaY0juR9xvUATjfWvasZTNUM/AlqqROJP3vkBkgsjdwAiaWxXw/Rfrdlp618XftLe53x+xttRPYjgxMg/BbaedJ/N76vi+W7etkG3RvKgUqugPyiSl9oXHyaWLuz+wWWaxRzabqKrcb3fVKviaA9LXqp9OuO1/D8jE3v+r45uHpiqwdle41lHiCRKKXkBkgsjtwAiaUx5QNMYSJ2exM7D3tvpy8R2+4zO/UQO9j4BubaF6MHKuupcY2sxP5N/90i8X7TO9nAxbYl3m+vfq73GSEcLeZVJrhSCtRaSE123Nv42OPc0bM8omrqj10OKpFYDrkBEksjN0Biaew3w+dxXJFNBHrIS3G2srNB4xpfz02CbozjC9EmJn/mGLWtLgb/+d13PU74NvIsiKlL0kEs+Rkt/IE/xV8y0Wvi90TIW9K8AGNcDJ7zx/Uk5C9pz+Dn3g/HO38gfwESSyM3QGJp5AZILA3RBp3Ru2wmtk3b3anAOHTWDdOORDz4ZD9gLOEwfXxFz57/cQMPhJr9M9x98nzMu2pCHTIdxo7rfre0WduD+jafH9ef6tsAgtS5mbwHnTD4eP1s8RiuWXhczv+cqUXm+PF+tE465hq1hh4LT90pkfjKkBsgsTRyAySWxj5V64njajjih+ylaztVamENf0bsfq4HS96ggyl6O6wlYG6hmZi07TNFbc0Y8h6O6xpo0e+vMzHvAVv7O9FnYKqG2Oh16vck/ry0XlnujPlnwLoC8Kau27WVmaYMFbym/AVILI3cAImlkRsgsTR27fkK23Q3PB9AOPS0mzGmGVvfae3P2OIuTqxMkTP+D96N/sbEGuSvBek8TofUcKJO6nuKzcoMCv0o9CiQ5cd2vPPrXC2BLFmailFDaZwVjlCJPyOZk32OjV+nC6Xf5Xp+OcR8IVfCkL8AiaWRGyCxNHIDJJaG1gRX2ky/TC2pi/G76l3Wg8bW6KdcndgfIP++1tjud7a+8zG0527sP/Ti+lI525d5g7hGohsD1tnrpUxwfgw01j5RhzDhs8n43eRhxEfi9wS+TYn9KMI/b9xXIX8BEksjN0BiaeQGSCyNKV2gfoCbTt6LsbNp6x/Cb7m2Rx0HhpBZaINibdv23H1nMNPbq6KPr+QBWCdwH3z0Ur55O6LdzDC95/kY7aNnn5f5Gan5xhjJmdD+jvsA2FyNOBnMkzjfzPRus5/Ftd9iczuJxGrIDZBYGrkBEktjd/oqoosPDr3Efbl9HnHs/+zxtc6Ec9whwtUSeE6O0esELH/G3Jc4JC/BC/A+GYeGThHNWomjS6m2i/fjVnBQXImH9H3rsV/Hv4nbtgVnS+F3ZsJlE1RTV1Bs/gSjxby/5jtNreep0YnEV4bcAImlkRsgsTRsHsDVABzO5nuyt6vTFXV2fzMxfuHT17g+4ZfSA3W5jib5EAmeYz1Ys9B2ntMAtXD+j43Zc9FOW9PZ09QMndGBjVbg+/hq6zN+4ZzWkDQdwMXX/l7+AiSWRm6AxNLIDZBYGntDcPX4ZSgzFt3Y5ZIfoG/wiO1+csrPjyzOvd7PxwRfRWBzCM95EK6GQWPzqMfYmJOhlmjsMzhtIqfEoxpB4zxzDvo2MSdJUedP41heSeyPOfTYlZuCcoSu73XGFK1EYj3kBkgsjdwAiaUheYBGLtAEJ0c43KzlnSCIxMrtRcgloggDu589BKj334zuJ21i4Ro5gj/syI2OkRTq0jfAaclp4FLEy7toFrH31uAIzYC6+C/oOSDPaDRJndaQ76QcgzqbM33BbN3w4dY5kVuge9In8irWz0kkFkNugMTSyA2QWBp7OZ/T8mccve60rYfNdzcaNTfG+1tsh1HTs07ZlDH3xmrkT4TyVQO0h/+h+j/oO4Y1352yUX28Hd76cMPmuOzP6qVibRNFzdtB/Vbwnajpyf4MNkcR2+KqcTTeg+R/eqzp6XIF0hPafO5Teq+JxGrIDZBYGrkBEktj3x6x7Uh+BePoYtUyho3z7/GvV3BUOu0z2JrN2K+yO9Gjl9o1rV730CWl/JiKeaNPFuL90h6X/omxL6n2v1EviP7PRvt4Qju/xJ8Fod3aqLUf37eJvT4espnvBnGyhrjjiQ2hZ6aPQdlZY4D3Lw2oZ+ofPo51wtfKeoBE4o/IDZBYGrkBEktjJ5emGv0fh04OOm1ZbCvh8TvNeBzTPmsmXus07LV6lH6CLBr/cDkQnAdbSmLhkpa4/jvieqjdSxxfP5xOkchpwlcx8W/mVRjjv3fjb0iuA6dNve/GUdX5MKxtYK8GxP4pQzXC+mXbrvNCh9QNx7pDrv9D/gIklkZugMTSyA2QWBo74/1iKk/UAzA/0IXbA71Oo5sp+jA8dvaZWYOWgIoRjWthVDIngH90GKGkzDResJt+Z6b8QTkqt3DMeUMu5Y41YMw2wXfS2mJweKTn7gD9Imo99QfvFcfs1Z5+vRxD9+R0Gj7gAmlNM9ZG/hX81c2Mn+FW5S9AYmnkBkgsjdwAiaWxO61Pq9EZm6MSYxZb0/gSU1oxXA+O1exn/1f6G7DvvyDuu4HRQ+7TIZwcruhan6fi2gN+QocdDK+lHMLh4eque3X1ymcf96VHIhyhco0uPLE4Bu9rFeK8xGnqPZhbODp9vGeVXc30v8gsicSfKXIDJJZGboDE0titfWz0OhkXpz/QTY8wq/uJW1ldywmN/4rYPDVwzlFuWo4a9+6VOgRXQ/yI+S3Py6jGXKnykOYC19Ps9EMGutTRsnaCuO5xJudL/LnzXUnfA9OfgfdlboS5i406p+KTuJ50rvb3WpNqQx18/gIklkZugMTSyA2QWBr7DO9f498GT85DOO6HTG96DL9SKPQ0mQPwlIrca4zprgbaaFn6PAbsS+qHCh+G1+4YH83iefCNcXfDrqJuj+8hQP9BmgVgDHIXUrPBpbl3xboFrZSO7mv7LvNWOJYcEV605EBMPUP+AiSWRm6AxNLIDZBYGrvrvzvVE8DV+DJvMNErwMHZ/QLEdCUXwSFiQsfrd8/CuHIzepdS02yKHoSj/xoLFb3ALudqJF/RZ/5m4f03VzdsdDxRA33SxxD/hPmBmAf1eh+aPMcxJpV6cdOvgE/fUW/APsSujlzrSahbOqE9lUishtwAiaWRGyCxNPaZGLzjC01x+idqi2fGOLxwRTbWbvg8Qm8xWqV14hn5D9r9pocAe1pVo7vKt8B34jhRDlU0ebA20QXiOzR6RLwvmixImy+pB8BwszZ7nt8H1mHjc6TWKvMnnLO3D1gna76TC5RIlFJyAyQWR26AxNKQPsHO+lYZTBMvl38h9ix3iOt0D8N1OSe08DfkGWZ8Eo33x5wTzT/EeQyr5L/zGVGUQN1V6vnIxaafsejZxzXQ0jdASoWp4YPT4AgJ36nHMXXhSrG3wDns7C6VxvHf1iq+BzWFXn4+uJTS7qN+wOoFsfHbFuc9Dvazu2d/gESilJIbILE4cgMklsbu4sqH0fd8dVvGEbQNDs/uGVOSP2O0LB2UH1JwTBuaN7vWwZzpB6wKoOD6257EbH4b90FjHfNmOPSsx6Xdr9qpvNd1/4HNaO9IzS74/afpQ8z33Fps0zuN0Zk81UT749LgjvGl5C9AYmnkBkgsjdwAiaWxu/+Q2KozYBFzVb6QsQXJx3iEQ7SHq9j9cd7g1dS5Cp+HPRAYw26sA3baOKiphe3bUGd8bOTqjGur/H2JMweslyDXpYLg0o0GDnuEbdKfC7F/m9wx/ZXpNPSYR6Q1xCT4I2/AW7GW4HgfLsdpCrVCHSHE9eVq3jf204rxdfMXILE0cgMklkZugMTS2Cvjx9LzdRxqJLzF/yH2luvZNI5dDL5RQ6bGuQjRkGGfMscFMrWw9Ad0nbCh4xnLttFXoUhqHIMnB13yDLTdrRaq4dVsqvL/+YAvJ/UD8ZynqUt2ddVcv/hsrB8w4X72Z6BfVFw+RyspwsON3wGz4kRiCeQGSCyN3ACJpbE729HZvo01oFKAec3ZkP4Ad2jDz3A5bP1AHP9Wfjn9CvoMrCXgNIjrbyZ+TLO/xzZlk05fN4zHs2DETB9fB7HLmd158J1s4fh2xp+F0xRytr7THmWug74Te5M5F0Z8P+SOTtPDWPWUkP8xf+rzFyCxNHIDJJZGboDE0tCaYNroTsu/Xdv6bs6GfltVuDfsoev0RmP+z8vBePB1XL8Yfc8iIxCPZyiZtq/pidapBSRxdPoJrMclR38c3voY041H5uoWfF9kPC9bJlCLE6NvN+MvYcnHjfwcOkaobYCPQZ/KcXXE7ZJ6Xxy6emjz7KyjqPUWjkkklkNugMTSyA2QWBo7bVbhskuNL+zRJ3U8m+mz63SE5PwBn4S6NKDAUDtIe8fGtbyiO2T4NoyFb0JsN7Y4hzAfYv68bKY219n6N2jaUGqoNBbwYkqueaefgHVyDbTXXfye68cjyucrbcpI/GJtCZ+dC6UGFP2BWAfp9N3qANYt4Ji6ohOzJBJfLXIDJJZGboDE0thP9qgSWg3ttnHoaCnP+gbUgXlB/L7xDmxC63j2qDHtzCcwfCzmYswX93wSxpVNDsHw45nTUA76OL5zzZ1pGcb13d8pzI/PS3uixfUS0i+M4XjYyo6PRA5YNx913eLcCzn9Dc7Wi6t5kBoV1BXEty0v6pG9HdHfu9dxdf4CJJZGboDE0sgNkFga/weRxoLp/1lsDQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=256x256 at 0x7FF692526610>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview a train data image\n",
    "print(train_labels[0])\n",
    "array_to_img(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_IAaxbXwAzF2",
    "outputId": "67d3dcc8-04ec-4b11-82da-d1806be9b83b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=256x256 at 0x7FF689F5DA00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview a test data image\n",
    "print(test_labels[0])\n",
    "array_to_img(test_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9rE7bNT8AzF3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHuwAxNVAzF3"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwnuxVWZAzF3"
   },
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIdfid5hAzF3"
   },
   "source": [
    "For our baseline model, we will create a simple Sequential Neural Network with one Convolutional Layer, one Max Pooling Layer, and one Dense Layer (not including our output layer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VUFKYIPmAzF3",
    "outputId": "dfffde53-f665-4606-e543-f3c6538683ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 516128)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                33032256  \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 33,033,802\n",
      "Trainable params: 33,033,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "baseline_model = Sequential()\n",
    "\n",
    "\n",
    "# Input Layer- Convolution\n",
    "baseline_model.add(Conv2D(filters=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          activation='relu',\n",
    "                          input_shape= (256, 256, 3)))\n",
    "\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "baseline_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2- connect all nodes with dense layer\n",
    "baseline_model.add(Flatten())\n",
    "baseline_model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "baseline_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "baseline_model.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FB11RqMEAzF3",
    "outputId": "3268cf17-8f4a-4c75-cd95-098475c1c0bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "148/148 [==============================] - 327s 2s/step - loss: 3.3877 - accuracy: 0.2939 - val_loss: 1.6197 - val_accuracy: 0.3700\n",
      "Epoch 2/20\n",
      "148/148 [==============================] - 353s 2s/step - loss: 1.5218 - accuracy: 0.4223 - val_loss: 1.4075 - val_accuracy: 0.4696\n",
      "Epoch 3/20\n",
      "148/148 [==============================] - 375s 3s/step - loss: 1.2251 - accuracy: 0.5588 - val_loss: 1.0713 - val_accuracy: 0.6007\n",
      "Epoch 4/20\n",
      "148/148 [==============================] - 310s 2s/step - loss: 1.0015 - accuracy: 0.6423 - val_loss: 1.0096 - val_accuracy: 0.6422\n",
      "Epoch 5/20\n",
      "148/148 [==============================] - 296s 2s/step - loss: 0.8978 - accuracy: 0.6808 - val_loss: 0.9568 - val_accuracy: 0.6426\n",
      "Epoch 6/20\n",
      "148/148 [==============================] - 296s 2s/step - loss: 0.8389 - accuracy: 0.7003 - val_loss: 0.9141 - val_accuracy: 0.6644\n",
      "Epoch 7/20\n",
      "148/148 [==============================] - 298s 2s/step - loss: 0.7665 - accuracy: 0.7302 - val_loss: 0.9494 - val_accuracy: 0.6615\n",
      "Epoch 8/20\n",
      "148/148 [==============================] - 296s 2s/step - loss: 0.7125 - accuracy: 0.7523 - val_loss: 0.9027 - val_accuracy: 0.6656\n",
      "Epoch 9/20\n",
      "148/148 [==============================] - 298s 2s/step - loss: 0.6604 - accuracy: 0.7748 - val_loss: 0.8528 - val_accuracy: 0.6907\n",
      "Epoch 10/20\n",
      "148/148 [==============================] - 323s 2s/step - loss: 0.5992 - accuracy: 0.8001 - val_loss: 0.8202 - val_accuracy: 0.7204\n",
      "Epoch 11/20\n",
      "148/148 [==============================] - 306s 2s/step - loss: 0.5203 - accuracy: 0.8258 - val_loss: 0.8082 - val_accuracy: 0.7163\n",
      "Epoch 12/20\n",
      "148/148 [==============================] - 328s 2s/step - loss: 0.4612 - accuracy: 0.8526 - val_loss: 0.8119 - val_accuracy: 0.7174\n",
      "Epoch 13/20\n",
      "148/148 [==============================] - 329s 2s/step - loss: 0.4023 - accuracy: 0.8755 - val_loss: 0.8557 - val_accuracy: 0.7115\n",
      "Epoch 14/20\n",
      "148/148 [==============================] - 309s 2s/step - loss: 0.3558 - accuracy: 0.8920 - val_loss: 0.8262 - val_accuracy: 0.7237\n",
      "Epoch 15/20\n",
      "148/148 [==============================] - 306s 2s/step - loss: 0.3132 - accuracy: 0.9081 - val_loss: 0.8719 - val_accuracy: 0.7167\n",
      "Epoch 16/20\n",
      "148/148 [==============================] - 314s 2s/step - loss: 0.2626 - accuracy: 0.9238 - val_loss: 0.8958 - val_accuracy: 0.7263\n",
      "Epoch 17/20\n",
      "148/148 [==============================] - 316s 2s/step - loss: 0.2401 - accuracy: 0.9327 - val_loss: 0.9385 - val_accuracy: 0.7033\n",
      "Epoch 18/20\n",
      "148/148 [==============================] - 320s 2s/step - loss: 0.1822 - accuracy: 0.9534 - val_loss: 0.9168 - val_accuracy: 0.7281\n",
      "Epoch 19/20\n",
      "148/148 [==============================] - 325s 2s/step - loss: 0.1773 - accuracy: 0.9526 - val_loss: 1.0057 - val_accuracy: 0.7167\n",
      "Epoch 20/20\n",
      "148/148 [==============================] - 317s 2s/step - loss: 0.1472 - accuracy: 0.9641 - val_loss: 1.0582 - val_accuracy: 0.7226\n"
     ]
    }
   ],
   "source": [
    "#Fit the model \n",
    "baseline_history = baseline_model.fit(train_generator, \n",
    "                                      epochs = 20, \n",
    "                                      batch_size= 128, \n",
    "                                      verbose = 1, \n",
    "                                      validation_data = val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEkMfN8uAzF4",
    "outputId": "767222a2-164b-4e56-9f57-dff888323d38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 25s 585ms/step - loss: 1.0459 - accuracy: 0.7411\n",
      "Test loss:  1.0459473133087158\n",
      "Test accuracy:  0.7411110997200012\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = baseline_model.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nY32LY7VAzF4"
   },
   "source": [
    "It looks like after 20 Epochs our baseline model overfit with a 96.4% train accuracy and a 74.1% test accuracy. In the future, we will also want to use Early Stopping to prevent the model from continuing to overfit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEEys1tgAzF4"
   },
   "source": [
    "### First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHrqIvBAAzF4"
   },
   "source": [
    "Let's make our CNN \"deeper\" and add additonal convolution and max pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2s-Cl4jAzF4",
    "outputId": "84846d79-7e08-49bd-afa8-7dde054410ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 125, 125, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 123008)            0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                7872576   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 7,883,370\n",
      "Trainable params: 7,883,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model_one = Sequential()\n",
    "\n",
    "\n",
    "# Input Layer- Convolution\n",
    "model_one.add(Conv2D(filters=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          activation='relu',\n",
    "                          input_shape= (256, 256, 3)))\n",
    "\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "model_one.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2- another convolution layer \n",
    "model_one.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 3- another max pool layer\n",
    "model_one.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 4- connect all nodes with dense layer\n",
    "model_one.add(Flatten())\n",
    "model_one.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "model_one.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "model_one.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model_one.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4lN_Dk5AzF5"
   },
   "source": [
    "Let's also add a stopping criteria as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlsLQQfbAzF5",
    "outputId": "ce69510c-4020-4911-ebf6-2143e446ae58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "148/148 [==============================] - 444s 3s/step - loss: 1.5299 - accuracy: 0.4476 - val_loss: 1.1410 - val_accuracy: 0.5926\n",
      "Epoch 2/20\n",
      "148/148 [==============================] - 452s 3s/step - loss: 1.0054 - accuracy: 0.6348 - val_loss: 0.9596 - val_accuracy: 0.6463\n",
      "Epoch 3/20\n",
      "148/148 [==============================] - 449s 3s/step - loss: 0.8038 - accuracy: 0.7134 - val_loss: 0.8036 - val_accuracy: 0.6993\n",
      "Epoch 4/20\n",
      "148/148 [==============================] - 490s 3s/step - loss: 0.6379 - accuracy: 0.7755 - val_loss: 0.7442 - val_accuracy: 0.7374\n",
      "Epoch 5/20\n",
      "148/148 [==============================] - 553s 4s/step - loss: 0.5075 - accuracy: 0.8248 - val_loss: 0.6600 - val_accuracy: 0.7711\n",
      "Epoch 6/20\n",
      "148/148 [==============================] - 451s 3s/step - loss: 0.4197 - accuracy: 0.8556 - val_loss: 0.7485 - val_accuracy: 0.7367\n",
      "Epoch 7/20\n",
      "148/148 [==============================] - 440s 3s/step - loss: 0.3318 - accuracy: 0.8915 - val_loss: 0.6621 - val_accuracy: 0.7807\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model_one_history = model_one.fit(train_generator, \n",
    "                                  epochs= 20, \n",
    "                                  validation_data = val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LzoxWKnAzF5",
    "outputId": "b7465a10-c586-4f02-b852-4bc39a441682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 36s 827ms/step - loss: 0.6744 - accuracy: 0.7857\n",
      "Test loss:  0.6743987798690796\n",
      "Test accuracy:  0.7857407331466675\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = model_one.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjPqzWWHAzF5"
   },
   "source": [
    "Making our model deeper and adding early stopping seemed to help; our model stopped after 7 Epochs once validation loss stopped decreasing. Our model is still overfit but less so with a 89.2% Train accuracy and a 78.6% Test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GcPQn-HAzF6"
   },
   "source": [
    "### Adding Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_C0yAQYzAzF6"
   },
   "source": [
    "To help with the consistent overfitting, let's try out a few regularization techniques: L1, L2, and Dropout Layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgok0pFhAzF6"
   },
   "source": [
    "#### Model 2- L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J54q8WtwAzF7",
    "outputId": "0acff9d5-99ff-46eb-cda3-049be830210e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 125, 125, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 123008)            0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                7872576   \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 7,883,370\n",
      "Trainable params: 7,883,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model_l1 = Sequential()\n",
    "\n",
    "\n",
    "# Input Layer- Convolution\n",
    "model_l1.add(Conv2D(filters=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          activation='relu',\n",
    "                          input_shape= (256, 256, 3),\n",
    "                     kernel_regularizer=regularizers.l1(0.005)))\n",
    "\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "model_l1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2- another convolution layer \n",
    "model_l1.add(layers.Conv2D(32, (3, 3), \n",
    "                            activation='relu', \n",
    "                            kernel_regularizer=regularizers.l1(0.005)))\n",
    "\n",
    "# Layer 3- another max pool layer\n",
    "model_l1.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 4- connect all nodes with dense layer\n",
    "model_l1.add(Flatten())\n",
    "model_l1.add(Dense(64, \n",
    "                    activation='relu', \n",
    "                    kernel_regularizer=regularizers.l1(0.005)))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "model_l1.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "model_l1.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model_l1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THU1ZdHMAzF7",
    "outputId": "69c2f0c8-f9b8-492f-dcec-dfee4ef5b093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "148/148 [==============================] - 442s 3s/step - loss: 13.5989 - accuracy: 0.1928 - val_loss: 7.3832 - val_accuracy: 0.2019\n",
      "Epoch 2/20\n",
      "148/148 [==============================] - 432s 3s/step - loss: 7.1454 - accuracy: 0.2334 - val_loss: 6.8890 - val_accuracy: 0.2422\n",
      "Epoch 3/20\n",
      "148/148 [==============================] - 433s 3s/step - loss: 6.8911 - accuracy: 0.2394 - val_loss: 6.7559 - val_accuracy: 0.2585\n",
      "Epoch 4/20\n",
      "148/148 [==============================] - 440s 3s/step - loss: 6.7881 - accuracy: 0.2473 - val_loss: 6.7858 - val_accuracy: 0.2333\n",
      "Epoch 5/20\n",
      "148/148 [==============================] - 426s 3s/step - loss: 6.7365 - accuracy: 0.2517 - val_loss: 6.7388 - val_accuracy: 0.2959\n",
      "Epoch 6/20\n",
      "148/148 [==============================] - 431s 3s/step - loss: 6.7060 - accuracy: 0.2513 - val_loss: 6.6780 - val_accuracy: 0.2541\n",
      "Epoch 7/20\n",
      "148/148 [==============================] - 428s 3s/step - loss: 6.6548 - accuracy: 0.2603 - val_loss: 6.6618 - val_accuracy: 0.2311\n",
      "Epoch 8/20\n",
      "148/148 [==============================] - 427s 3s/step - loss: 6.6269 - accuracy: 0.2657 - val_loss: 6.5992 - val_accuracy: 0.2730\n",
      "Epoch 9/20\n",
      "148/148 [==============================] - 429s 3s/step - loss: 6.6214 - accuracy: 0.2676 - val_loss: 6.5711 - val_accuracy: 0.2615\n",
      "Epoch 10/20\n",
      "148/148 [==============================] - 431s 3s/step - loss: 6.5939 - accuracy: 0.2741 - val_loss: 6.7074 - val_accuracy: 0.2441\n",
      "Epoch 11/20\n",
      "148/148 [==============================] - 428s 3s/step - loss: 6.5794 - accuracy: 0.2789 - val_loss: 6.5057 - val_accuracy: 0.2648\n",
      "Epoch 12/20\n",
      "148/148 [==============================] - 436s 3s/step - loss: 6.5395 - accuracy: 0.2841 - val_loss: 6.5433 - val_accuracy: 0.3022\n",
      "Epoch 13/20\n",
      "148/148 [==============================] - 437s 3s/step - loss: 6.5210 - accuracy: 0.2904 - val_loss: 6.6076 - val_accuracy: 0.2556\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model_l1_history = model_l1.fit(train_generator, \n",
    "                                  epochs= 20, \n",
    "                                  validation_data = val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAPsNJOuAzF7",
    "outputId": "10a66788-32c8-4dd8-a81a-65b58b9ff0ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 33s 768ms/step - loss: 6.5977 - accuracy: 0.2669\n",
      "Test loss:  6.597667217254639\n",
      "Test accuracy:  0.26685184240341187\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = model_l1.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bVIxnMTAzF7"
   },
   "source": [
    "#### Model 3- L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgTlZQhOAzF7",
    "outputId": "6bab477a-8fa0-433c-cdcb-26a417b4604a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 125, 125, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 123008)            0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                7872576   \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 7,883,370\n",
      "Trainable params: 7,883,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model_l2 = Sequential()\n",
    "\n",
    "\n",
    "# Input Layer- Convolution\n",
    "model_l2.add(Conv2D(filters=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          activation='relu',\n",
    "                          input_shape= (256, 256, 3),\n",
    "                     kernel_regularizer=regularizers.l2(0.005)))\n",
    "\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "model_l2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2- another convolution layer \n",
    "model_l2.add(layers.Conv2D(32, (3, 3), \n",
    "                            activation='relu', \n",
    "                            kernel_regularizer=regularizers.l2(0.005)))\n",
    "\n",
    "# Layer 3- another max pool layer\n",
    "model_l2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 4- connect all nodes with dense layer\n",
    "model_l2.add(Flatten())\n",
    "model_l2.add(Dense(64, \n",
    "                    activation='relu', \n",
    "                    kernel_regularizer=regularizers.l2(0.005)))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "model_l2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "model_l2.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model_l2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSZCxTV1AzF8",
    "outputId": "07979bac-6e35-4474-ad42-1fdda1e8d43d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "148/148 [==============================] - 432s 3s/step - loss: 2.1379 - accuracy: 0.3422 - val_loss: 1.9591 - val_accuracy: 0.3393\n",
      "Epoch 2/20\n",
      "148/148 [==============================] - 430s 3s/step - loss: 1.6320 - accuracy: 0.4792 - val_loss: 1.5435 - val_accuracy: 0.4852\n",
      "Epoch 3/20\n",
      "148/148 [==============================] - 430s 3s/step - loss: 1.4293 - accuracy: 0.5686 - val_loss: 1.3838 - val_accuracy: 0.5859\n",
      "Epoch 4/20\n",
      "148/148 [==============================] - 431s 3s/step - loss: 1.3499 - accuracy: 0.5898 - val_loss: 1.3529 - val_accuracy: 0.5700\n",
      "Epoch 5/20\n",
      "148/148 [==============================] - 437s 3s/step - loss: 1.2759 - accuracy: 0.6182 - val_loss: 1.2808 - val_accuracy: 0.6100\n",
      "Epoch 6/20\n",
      "148/148 [==============================] - 430s 3s/step - loss: 1.2131 - accuracy: 0.6368 - val_loss: 1.1424 - val_accuracy: 0.6789\n",
      "Epoch 7/20\n",
      "148/148 [==============================] - 429s 3s/step - loss: 1.1644 - accuracy: 0.6528 - val_loss: 1.1429 - val_accuracy: 0.6578\n",
      "Epoch 8/20\n",
      "148/148 [==============================] - 432s 3s/step - loss: 1.1263 - accuracy: 0.6613 - val_loss: 1.1465 - val_accuracy: 0.6585\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model_l2_history = model_l2.fit(train_generator, \n",
    "                                  epochs= 20, \n",
    "                                  validation_data = val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TGslLDKFAzF8",
    "outputId": "d161add8-e0b2-459d-a715-d2179f587ac2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 35s 806ms/step - loss: 1.1507 - accuracy: 0.6563\n",
      "Test loss:  1.150733232498169\n",
      "Test accuracy:  0.6562963128089905\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = model_l2.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKZ_oj7EAzF8"
   },
   "source": [
    "#### Model 4- Dropout Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "phuuEiQLAzF8",
    "outputId": "d6bc0f1d-30a8-47be-cba7-3b4dc7eca3a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_10 (Dropout)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 125, 125, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 123008)            0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 64)                7872576   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 7,883,370\n",
      "Trainable params: 7,883,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model_dropout = Sequential()\n",
    "\n",
    "\n",
    "# Input Layer- Dropout\n",
    "model_dropout.add(layers.Dropout(0.2, input_shape= (256, 256, 3)))\n",
    "\n",
    "#Convolution Layer\n",
    "model_dropout.add(Conv2D(filters=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          activation='relu'))\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "model_dropout.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_dropout.add(layers.Dropout(0.2))\n",
    "\n",
    "# Layer 2- another convolution layer \n",
    "model_dropout.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 3- another max pool layer\n",
    "model_dropout.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_dropout.add(layers.Dropout(0.2))\n",
    "\n",
    "# Layer 4- connect all nodes with dense layer\n",
    "model_dropout.add(Flatten())\n",
    "model_dropout.add(Dense(64, activation='relu'))\n",
    "\n",
    "model_dropout.add(layers.Dropout(0.2))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "model_dropout.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "model_dropout.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "soMD5CkSAzF8",
    "outputId": "6f9eaf3e-7cab-4ecf-8d18-afc423d7eba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "148/148 [==============================] - 517s 3s/step - loss: 2.4970 - accuracy: 0.1553 - val_loss: 2.1980 - val_accuracy: 0.1674\n",
      "Epoch 2/20\n",
      "148/148 [==============================] - 514s 3s/step - loss: 1.9059 - accuracy: 0.2441 - val_loss: 2.0253 - val_accuracy: 0.2404\n",
      "Epoch 3/20\n",
      "148/148 [==============================] - 513s 3s/step - loss: 1.7884 - accuracy: 0.2856 - val_loss: 1.8434 - val_accuracy: 0.3511\n",
      "Epoch 4/20\n",
      "148/148 [==============================] - 514s 3s/step - loss: 1.7333 - accuracy: 0.3106 - val_loss: 1.7482 - val_accuracy: 0.3663\n",
      "Epoch 5/20\n",
      "148/148 [==============================] - 512s 3s/step - loss: 1.6867 - accuracy: 0.3358 - val_loss: 1.7402 - val_accuracy: 0.3463\n",
      "Epoch 6/20\n",
      "148/148 [==============================] - 513s 3s/step - loss: 1.6566 - accuracy: 0.3614 - val_loss: 1.6861 - val_accuracy: 0.3889\n",
      "Epoch 7/20\n",
      "148/148 [==============================] - 519s 4s/step - loss: 1.5778 - accuracy: 0.4080 - val_loss: 1.8090 - val_accuracy: 0.3348\n",
      "Epoch 8/20\n",
      "148/148 [==============================] - 512s 3s/step - loss: 1.5274 - accuracy: 0.4299 - val_loss: 1.7019 - val_accuracy: 0.3752\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model_dropout_history = model_dropout.fit(train_generator, \n",
    "                                  epochs= 20, \n",
    "                                  validation_data = val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEP2QxsmAzF9",
    "outputId": "d1b03292-bb82-441b-c09d-c35e9e7e46ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 33s 774ms/step - loss: 1.7064 - accuracy: 0.3637\n",
      "Test loss:  1.7064480781555176\n",
      "Test accuracy:  0.3637036979198456\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = model_dropout.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y0WBYcvTAzF9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNMP0TFiAzF9"
   },
   "source": [
    "#### Model 5- Dropout and L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZuooflMAzF9",
    "outputId": "1d375878-a12b-441c-e3da-1438c685cef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 125, 125, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 123008)            0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 32)                3936288   \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 3,949,194\n",
      "Trainable params: 3,949,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model_five = Sequential()\n",
    "\n",
    "# Input Layer- Convolution\n",
    "model_five.add(Conv2D(filters=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          activation='relu',\n",
    "                          input_shape= (256, 256, 3),\n",
    "                     kernel_regularizer=regularizers.l2(0.005)))\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "model_five.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_five.add(layers.Dropout(0.2))\n",
    "\n",
    "# Layer 2- another convolution layer \n",
    "model_five.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
    "\n",
    "# Layer 3- another max pool layer\n",
    "model_five.add(layers.MaxPooling2D((2, 2)))\n",
    "model_five.add(layers.Dropout(0.2))\n",
    "\n",
    "# Layer 4- connect all nodes with dense layer\n",
    "model_five.add(Flatten())\n",
    "model_five.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
    "\n",
    "#Layer 5\n",
    "model_five.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "model_five.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "model_five.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model_five.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbUzRiT9AzF9",
    "outputId": "252d7e32-cbc4-475c-a28d-70589f062b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "148/148 [==============================] - 490s 3s/step - loss: 2.4675 - accuracy: 0.1976 - val_loss: 1.9717 - val_accuracy: 0.3196\n",
      "Epoch 2/20\n",
      "148/148 [==============================] - 490s 3s/step - loss: 1.8828 - accuracy: 0.3471 - val_loss: 1.7990 - val_accuracy: 0.3978\n",
      "Epoch 3/20\n",
      "148/148 [==============================] - 490s 3s/step - loss: 1.7338 - accuracy: 0.4206 - val_loss: 1.6767 - val_accuracy: 0.4407\n",
      "Epoch 4/20\n",
      "148/148 [==============================] - 491s 3s/step - loss: 1.6063 - accuracy: 0.4655 - val_loss: 1.5370 - val_accuracy: 0.5059\n",
      "Epoch 5/20\n",
      "148/148 [==============================] - 490s 3s/step - loss: 1.5095 - accuracy: 0.5031 - val_loss: 1.4821 - val_accuracy: 0.5026\n",
      "Epoch 6/20\n",
      "148/148 [==============================] - 502s 3s/step - loss: 1.4447 - accuracy: 0.5267 - val_loss: 1.4239 - val_accuracy: 0.5456\n",
      "Epoch 7/20\n",
      "148/148 [==============================] - 490s 3s/step - loss: 1.4236 - accuracy: 0.5341 - val_loss: 1.4637 - val_accuracy: 0.5156\n",
      "Epoch 8/20\n",
      "148/148 [==============================] - 490s 3s/step - loss: 1.3587 - accuracy: 0.5542 - val_loss: 1.4379 - val_accuracy: 0.5337\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model_five_history = model_five.fit(train_generator, \n",
    "                                  epochs= 20, \n",
    "                                  validation_data = val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AdrV3QuaAzF9",
    "outputId": "4d2955b5-8cd5-4afc-84fc-190e430b6d9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 32s 754ms/step - loss: 1.4017 - accuracy: 0.5459\n",
      "Test loss:  1.4017235040664673\n",
      "Test accuracy:  0.5459259152412415\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = model_five.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnc8jps8AzF-"
   },
   "source": [
    "### Model 6- Increasing initial Convolution Layer's Filter and Kernal size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vt7XW51yAzF-"
   },
   "source": [
    "Also arranged Dense layers in decreasing order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QW6A4r8HAzF-",
    "outputId": "7affe412-da5d-4892-f2b7-fd8b364a7899"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 252, 252, 64)      4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 126, 126, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 124, 124, 32)      18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 123008)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                7872576   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 7,898,314\n",
      "Trainable params: 7,898,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model_six = Sequential()\n",
    "\n",
    "# Input Layer- Convolution\n",
    "model_six.add(Conv2D(filters=64,\n",
    "                          kernel_size=(5, 5),\n",
    "                          activation='relu',\n",
    "                          input_shape= (256, 256, 3)))\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "model_six.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2- another convolution layer \n",
    "model_six.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 3- another max pool layer\n",
    "model_six.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 4- connect all nodes with dense layer\n",
    "model_six.add(Flatten())\n",
    "model_six.add(Dense(64, activation='relu'))\n",
    "\n",
    "#Layer 5\n",
    "model_six.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "model_six.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "model_six.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model_six.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-B_kyOaAzF-",
    "outputId": "1692e907-81ed-4ddb-e337-d7a4136efb29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "148/148 [==============================] - 1051s 7s/step - loss: 2.0885 - accuracy: 0.2260 - val_loss: 1.8681 - val_accuracy: 0.2626\n",
      "Epoch 2/20\n",
      "148/148 [==============================] - 1014s 7s/step - loss: 1.7389 - accuracy: 0.3028 - val_loss: 1.6575 - val_accuracy: 0.3219\n",
      "Epoch 3/20\n",
      "148/148 [==============================] - 996s 7s/step - loss: 1.5863 - accuracy: 0.3687 - val_loss: 1.5469 - val_accuracy: 0.4181\n",
      "Epoch 4/20\n",
      "148/148 [==============================] - 974s 7s/step - loss: 1.5005 - accuracy: 0.4251 - val_loss: 1.4903 - val_accuracy: 0.4241\n",
      "Epoch 5/20\n",
      "148/148 [==============================] - 955s 6s/step - loss: 1.4163 - accuracy: 0.4676 - val_loss: 1.4474 - val_accuracy: 0.4526\n",
      "Epoch 6/20\n",
      "148/148 [==============================] - 957s 6s/step - loss: 1.3258 - accuracy: 0.5107 - val_loss: 1.4705 - val_accuracy: 0.4389\n",
      "Epoch 7/20\n",
      "148/148 [==============================] - 945s 6s/step - loss: 1.2367 - accuracy: 0.5442 - val_loss: 1.3537 - val_accuracy: 0.4919\n",
      "Epoch 8/20\n",
      "148/148 [==============================] - 963s 7s/step - loss: 1.1416 - accuracy: 0.5841 - val_loss: 1.3715 - val_accuracy: 0.5048\n",
      "Epoch 9/20\n",
      "148/148 [==============================] - 956s 6s/step - loss: 1.0401 - accuracy: 0.6261 - val_loss: 1.2836 - val_accuracy: 0.5393\n",
      "Epoch 10/20\n",
      "148/148 [==============================] - 949s 6s/step - loss: 0.9935 - accuracy: 0.6438 - val_loss: 1.3660 - val_accuracy: 0.5148\n",
      "Epoch 11/20\n",
      "148/148 [==============================] - 960s 6s/step - loss: 0.9111 - accuracy: 0.6721 - val_loss: 1.4051 - val_accuracy: 0.5300\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model_six_history = model_six.fit(train_generator, \n",
    "                                  epochs= 20, \n",
    "                                  validation_data = val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taXwk4xNAzF-",
    "outputId": "7b2addba-80c5-4686-ed5a-04378cf57d4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 59s 1s/step - loss: 1.3475 - accuracy: 0.5319\n",
      "Test loss:  1.3474699258804321\n",
      "Test accuracy:  0.5318518280982971\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = model_six.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8YBxfCnAzF-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWLDU44_AzF-"
   },
   "source": [
    "### Model 7- Add Dense(128) Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3T2C5Go9AzF_",
    "outputId": "370250be-a404-4188-c8b3-47af16996c0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 125, 125, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 123008)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               15745152  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 15,765,962\n",
      "Trainable params: 15,765,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model_seven = Sequential()\n",
    "\n",
    "# Input Layer- Convolution\n",
    "model_seven.add(Conv2D(filters=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          activation='relu',\n",
    "                          input_shape= (256, 256, 3)))\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "model_seven.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2- another convolution layer \n",
    "model_seven.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 3- another max pool layer\n",
    "model_seven.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 4- connect all nodes with dense layer\n",
    "model_seven.add(Flatten())\n",
    "model_seven.add(Dense(128, activation='relu'))                \n",
    "                \n",
    "# Layer 5- dense layer                \n",
    "model_seven.add(Dense(64, activation='relu'))\n",
    "                \n",
    "# Layer 6- dense layer  \n",
    "model_seven.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "model_seven.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "model_seven.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model_seven.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bnA0ed59AzF_",
    "outputId": "9ec7e7ae-8432-4fe4-f60a-b4a3a878369f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "148/148 [==============================] - 431s 3s/step - loss: 1.7042 - accuracy: 0.3772 - val_loss: 1.3390 - val_accuracy: 0.5141\n",
      "Epoch 2/20\n",
      "148/148 [==============================] - 429s 3s/step - loss: 1.2923 - accuracy: 0.5213 - val_loss: 1.2157 - val_accuracy: 0.5633\n",
      "Epoch 3/20\n",
      "148/148 [==============================] - 429s 3s/step - loss: 1.1309 - accuracy: 0.5794 - val_loss: 1.1131 - val_accuracy: 0.5915\n",
      "Epoch 4/20\n",
      "148/148 [==============================] - 427s 3s/step - loss: 1.0286 - accuracy: 0.6232 - val_loss: 1.0793 - val_accuracy: 0.6115\n",
      "Epoch 5/20\n",
      "148/148 [==============================] - 429s 3s/step - loss: 0.9325 - accuracy: 0.6661 - val_loss: 0.9119 - val_accuracy: 0.6815\n",
      "Epoch 6/20\n",
      "148/148 [==============================] - 429s 3s/step - loss: 0.7214 - accuracy: 0.7420 - val_loss: 0.7592 - val_accuracy: 0.7244\n",
      "Epoch 7/20\n",
      "148/148 [==============================] - 433s 3s/step - loss: 0.5805 - accuracy: 0.7905 - val_loss: 0.7856 - val_accuracy: 0.7289\n",
      "Epoch 8/20\n",
      "148/148 [==============================] - 429s 3s/step - loss: 0.4392 - accuracy: 0.8489 - val_loss: 0.7429 - val_accuracy: 0.7504\n",
      "Epoch 9/20\n",
      "148/148 [==============================] - 429s 3s/step - loss: 0.3402 - accuracy: 0.8849 - val_loss: 0.8058 - val_accuracy: 0.7430\n",
      "Epoch 10/20\n",
      "148/148 [==============================] - 431s 3s/step - loss: 0.2509 - accuracy: 0.9196 - val_loss: 0.7860 - val_accuracy: 0.7596\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = EarlyStopping(monitor='val_loss', mode='min', verbose = 1, patience = 2)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model_seven_history = model_seven.fit(train_generator, \n",
    "                                  epochs= 20, \n",
    "                                  validation_data = val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZasdjbdAzF_",
    "outputId": "c8a061e0-de8b-478a-9e5a-6be2cd6503e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 33s 758ms/step - loss: 0.7563 - accuracy: 0.7769\n",
      "Test loss:  0.7563361525535583\n",
      "Test accuracy:  0.7768518328666687\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = model_seven.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oyMrfSq9AzGA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ja3QvzByAzGA"
   },
   "source": [
    "### Model 8- Deeper CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrjvgQJEAzGA"
   },
   "source": [
    "Adding another Convolutional with Max Pooling Layer.  Also changing our EarlyStopping callback to monitor validation accuracy instead of validation loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W03EaByCAzGA",
    "outputId": "df52b576-bd20-433b-ca0b-d31919b51a15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 125, 125, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 60, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                1843264   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,867,466\n",
      "Trainable params: 1,867,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model_eight = Sequential()\n",
    "\n",
    "\n",
    "# Input Layer- Convolution\n",
    "model_eight.add(Conv2D(filters=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          activation='relu',\n",
    "                          input_shape= (256, 256, 3)))\n",
    "\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "model_eight.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2- another convolution layer \n",
    "model_eight.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 3- another max pool layer\n",
    "model_eight.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 4- another convolution layer \n",
    "model_eight.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 5- another max pool layer\n",
    "model_eight.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 6- connect all nodes with dense layer\n",
    "model_eight.add(Flatten())\n",
    "model_eight.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Layer 7- dense layer\n",
    "model_eight.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "model_eight.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "model_eight.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model_eight.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-_f1rzHAzGA",
    "outputId": "d7f2d6db-d4a8-46e2-fcdb-6b5e839ef4f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "148/148 [==============================] - 527s 4s/step - loss: 1.6420 - accuracy: 0.3805 - val_loss: 1.2893 - val_accuracy: 0.5274\n",
      "Epoch 2/20\n",
      "148/148 [==============================] - 574s 4s/step - loss: 1.1483 - accuracy: 0.5761 - val_loss: 1.0552 - val_accuracy: 0.6193\n",
      "Epoch 3/20\n",
      "148/148 [==============================] - 586s 4s/step - loss: 0.9700 - accuracy: 0.6397 - val_loss: 0.8785 - val_accuracy: 0.6837\n",
      "Epoch 4/20\n",
      "148/148 [==============================] - 501s 3s/step - loss: 0.7638 - accuracy: 0.7220 - val_loss: 0.8687 - val_accuracy: 0.6863\n",
      "Epoch 5/20\n",
      "148/148 [==============================] - 478s 3s/step - loss: 0.6472 - accuracy: 0.7644 - val_loss: 0.7288 - val_accuracy: 0.7363\n",
      "Epoch 6/20\n",
      "148/148 [==============================] - 568s 4s/step - loss: 0.5564 - accuracy: 0.7957 - val_loss: 0.6097 - val_accuracy: 0.7800\n",
      "Epoch 7/20\n",
      "148/148 [==============================] - 547s 4s/step - loss: 0.4814 - accuracy: 0.8262 - val_loss: 0.6907 - val_accuracy: 0.7600\n",
      "Epoch 8/20\n",
      "148/148 [==============================] - 508s 3s/step - loss: 0.4337 - accuracy: 0.8431 - val_loss: 0.5844 - val_accuracy: 0.7889\n",
      "Epoch 9/20\n",
      "148/148 [==============================] - 548s 4s/step - loss: 0.3971 - accuracy: 0.8590 - val_loss: 0.6085 - val_accuracy: 0.7859\n",
      "Epoch 10/20\n",
      "148/148 [==============================] - 503s 3s/step - loss: 0.3338 - accuracy: 0.8838 - val_loss: 0.6405 - val_accuracy: 0.7837\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 2)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model_eight_history = model_eight.fit(train_generator, \n",
    "                                  epochs= 20, \n",
    "                                  validation_data = val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wveApKWIAzGA",
    "outputId": "86ad5322-70a1-461a-9b22-527fc93059a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 36s 846ms/step - loss: 0.6190 - accuracy: 0.7902\n",
      "Test loss:  0.619040846824646\n",
      "Test accuracy:  0.7901852130889893\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = model_eight.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZ8sT6SrAzGB"
   },
   "source": [
    "### Model 9- Deeper CNN with 0.5 Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9iEv6d0AzGB"
   },
   "source": [
    "Adding two 0.5 Dropout Layers after two Dense layers to help address overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYnaZOQ_AzGB",
    "outputId": "ce0f275a-7631-46af-bd0d-def4734becd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 125, 125, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 60, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                1843264   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 1,865,066\n",
      "Trainable params: 1,865,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model_nine = Sequential()\n",
    "\n",
    "\n",
    "# Input Layer- Convolution\n",
    "model_nine.add(Conv2D(filters=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          activation='relu',\n",
    "                          input_shape= (256, 256, 3)))\n",
    "\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "model_nine.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2- another convolution layer \n",
    "model_nine.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 3- another max pool layer\n",
    "model_nine.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 4- another convolution layer \n",
    "model_nine.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 5- another max pool layer\n",
    "model_nine.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 6- connect all nodes with dense layer\n",
    "model_nine.add(Flatten())\n",
    "model_nine.add(Dense(64, activation='relu'))\n",
    "model_nine.add(layers.Dropout(0.5))\n",
    "\n",
    "# Layer 7- dense layer\n",
    "model_nine.add(Dense(32, activation='relu'))\n",
    "model_nine.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "model_nine.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "model_nine.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model_nine.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAHmuIuMAzGB",
    "outputId": "3e975c93-539d-4bd7-fd51-3be3a8a3474d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "148/148 [==============================] - 515s 3s/step - loss: 2.0381 - accuracy: 0.2160 - val_loss: 1.6584 - val_accuracy: 0.3137\n",
      "Epoch 2/20\n",
      "148/148 [==============================] - 539s 4s/step - loss: 1.7128 - accuracy: 0.3208 - val_loss: 1.4542 - val_accuracy: 0.4937\n",
      "Epoch 3/20\n",
      "148/148 [==============================] - 482s 3s/step - loss: 1.5734 - accuracy: 0.3838 - val_loss: 1.3543 - val_accuracy: 0.5067\n",
      "Epoch 4/20\n",
      "148/148 [==============================] - 475s 3s/step - loss: 1.4843 - accuracy: 0.4311 - val_loss: 1.2336 - val_accuracy: 0.5541\n",
      "Epoch 5/20\n",
      "148/148 [==============================] - 475s 3s/step - loss: 1.4023 - accuracy: 0.4672 - val_loss: 1.1401 - val_accuracy: 0.5885\n",
      "Epoch 6/20\n",
      "148/148 [==============================] - 477s 3s/step - loss: 1.3401 - accuracy: 0.4953 - val_loss: 1.0915 - val_accuracy: 0.6515\n",
      "Epoch 7/20\n",
      "148/148 [==============================] - 538s 4s/step - loss: 1.2818 - accuracy: 0.5334 - val_loss: 1.0660 - val_accuracy: 0.6463\n",
      "Epoch 8/20\n",
      "148/148 [==============================] - 536s 4s/step - loss: 1.2300 - accuracy: 0.5551 - val_loss: 0.9922 - val_accuracy: 0.6741\n",
      "Epoch 9/20\n",
      "148/148 [==============================] - 503s 3s/step - loss: 1.1809 - accuracy: 0.5719 - val_loss: 0.9365 - val_accuracy: 0.6841\n",
      "Epoch 10/20\n",
      "148/148 [==============================] - 507s 3s/step - loss: 1.1222 - accuracy: 0.5968 - val_loss: 0.8946 - val_accuracy: 0.7174\n",
      "Epoch 11/20\n",
      "148/148 [==============================] - 554s 4s/step - loss: 1.0781 - accuracy: 0.6135 - val_loss: 0.9728 - val_accuracy: 0.6652\n",
      "Epoch 12/20\n",
      "148/148 [==============================] - 606s 4s/step - loss: 1.0273 - accuracy: 0.6298 - val_loss: 0.8342 - val_accuracy: 0.7185\n",
      "Epoch 13/20\n",
      "148/148 [==============================] - 572s 4s/step - loss: 0.9910 - accuracy: 0.6461 - val_loss: 0.8403 - val_accuracy: 0.7022\n",
      "Epoch 14/20\n",
      "148/148 [==============================] - 496s 3s/step - loss: 0.9381 - accuracy: 0.6638 - val_loss: 0.7685 - val_accuracy: 0.7493\n",
      "Epoch 15/20\n",
      "148/148 [==============================] - 505s 3s/step - loss: 0.9261 - accuracy: 0.6722 - val_loss: 0.7644 - val_accuracy: 0.7448\n",
      "Epoch 16/20\n",
      "148/148 [==============================] - 481s 3s/step - loss: 0.8680 - accuracy: 0.6907 - val_loss: 0.7356 - val_accuracy: 0.7611\n",
      "Epoch 17/20\n",
      "148/148 [==============================] - 496s 3s/step - loss: 0.8666 - accuracy: 0.6947 - val_loss: 0.7464 - val_accuracy: 0.7556\n",
      "Epoch 18/20\n",
      "148/148 [==============================] - 475s 3s/step - loss: 0.8222 - accuracy: 0.7078 - val_loss: 0.7817 - val_accuracy: 0.7344\n",
      "Epoch 00018: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 2)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model_nine_history = model_nine.fit(train_generator, \n",
    "                                  epochs= 20, \n",
    "                                  validation_data = val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xAkqgCw_AzGB",
    "outputId": "c8116956-2c74-456c-eda7-c0c3d0639cb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 41s 961ms/step - loss: 0.7606 - accuracy: 0.7452\n",
      "Test loss:  0.760615348815918\n",
      "Test accuracy:  0.7451851963996887\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = model_nine.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DABtFT_oAzGB"
   },
   "source": [
    "### Model 10- Add Dense (16) and 0.2 Dropout Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTs6jFD-AzGC"
   },
   "source": [
    "Also increased number of Epochs to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtcrN6XiAzGC",
    "outputId": "fbd4583d-7677-44e1-ecb7-68f62508fb69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 125, 125, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 60, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                1843264   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 1,865,434\n",
      "Trainable params: 1,865,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model_ten = Sequential()\n",
    "\n",
    "\n",
    "# Input Layer- Convolution\n",
    "model_ten.add(Conv2D(filters=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          activation='relu',\n",
    "                          input_shape= (256, 256, 3)))\n",
    "\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "model_ten.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2- another convolution layer \n",
    "model_ten.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 3- another max pool layer\n",
    "model_ten.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 4- another convolution layer \n",
    "model_ten.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 5- another max pool layer\n",
    "model_ten.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 6- connect all nodes with dense layer\n",
    "model_ten.add(Flatten())\n",
    "model_ten.add(Dense(64, activation='relu'))\n",
    "model_ten.add(layers.Dropout(0.2))\n",
    "\n",
    "# Layer 7- dense layer\n",
    "model_ten.add(Dense(32, activation='relu'))\n",
    "model_ten.add(layers.Dropout(0.2))\n",
    "\n",
    "# Layer 7- dense layer\n",
    "model_ten.add(Dense(16, activation='relu'))\n",
    "model_ten.add(layers.Dropout(0.2))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "model_ten.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "model_ten.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model_ten.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEnJDx4kAzGC",
    "outputId": "652a50b2-2afd-4b0c-bfbc-784dca6f1eb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "148/148 [==============================] - 622s 4s/step - loss: 2.0001 - accuracy: 0.2441 - val_loss: 1.4877 - val_accuracy: 0.4644\n",
      "Epoch 2/50\n",
      "148/148 [==============================] - 544s 4s/step - loss: 1.5896 - accuracy: 0.3908 - val_loss: 1.2697 - val_accuracy: 0.5296\n",
      "Epoch 3/50\n",
      "148/148 [==============================] - 521s 4s/step - loss: 1.4313 - accuracy: 0.4567 - val_loss: 1.2073 - val_accuracy: 0.5552\n",
      "Epoch 4/50\n",
      "148/148 [==============================] - 520s 4s/step - loss: 1.3009 - accuracy: 0.5120 - val_loss: 1.0292 - val_accuracy: 0.6367\n",
      "Epoch 5/50\n",
      "148/148 [==============================] - 519s 4s/step - loss: 1.1568 - accuracy: 0.5681 - val_loss: 0.9088 - val_accuracy: 0.6719\n",
      "Epoch 6/50\n",
      "148/148 [==============================] - 528s 4s/step - loss: 1.0614 - accuracy: 0.6100 - val_loss: 0.8606 - val_accuracy: 0.7063\n",
      "Epoch 7/50\n",
      "148/148 [==============================] - 522s 4s/step - loss: 0.9663 - accuracy: 0.6494 - val_loss: 0.8364 - val_accuracy: 0.6933\n",
      "Epoch 8/50\n",
      "148/148 [==============================] - 487s 3s/step - loss: 0.9072 - accuracy: 0.6733 - val_loss: 0.8075 - val_accuracy: 0.7385\n",
      "Epoch 9/50\n",
      "148/148 [==============================] - 498s 3s/step - loss: 0.8207 - accuracy: 0.7096 - val_loss: 0.7680 - val_accuracy: 0.7463\n",
      "Epoch 10/50\n",
      "148/148 [==============================] - 509s 3s/step - loss: 0.7634 - accuracy: 0.7321 - val_loss: 0.7371 - val_accuracy: 0.7604\n",
      "Epoch 11/50\n",
      "148/148 [==============================] - 456s 3s/step - loss: 0.7232 - accuracy: 0.7505 - val_loss: 0.7084 - val_accuracy: 0.7767\n",
      "Epoch 12/50\n",
      "148/148 [==============================] - 485s 3s/step - loss: 0.6728 - accuracy: 0.7715 - val_loss: 0.7213 - val_accuracy: 0.7663\n",
      "Epoch 13/50\n",
      "148/148 [==============================] - 577s 4s/step - loss: 0.6131 - accuracy: 0.7892 - val_loss: 0.7271 - val_accuracy: 0.7567\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 2)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model_ten_history = model_ten.fit(train_generator, \n",
    "                                  epochs= 50, \n",
    "                                  validation_data = val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dEuaRbqAzGC",
    "outputId": "acd702e1-dafa-4418-ad4f-dc488e5ff6e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 36s 839ms/step - loss: 0.7133 - accuracy: 0.7635\n",
      "Test loss:  0.7133249044418335\n",
      "Test accuracy:  0.7635185122489929\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = model_ten.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkECx578AzGC"
   },
   "source": [
    "### Model 11- Wider CNN with 0.2 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EB1G-XD7AzGD",
    "outputId": "9d27ef5a-b327-4829-a694-943eeb270d86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 125, 125, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               14746112  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 14,905,386\n",
      "Trainable params: 14,905,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model_eleven = Sequential()\n",
    "\n",
    "\n",
    "# Input Layer- Convolution\n",
    "model_eleven.add(Conv2D(filters=32,\n",
    "                          kernel_size=(3, 3),\n",
    "                          activation='relu',\n",
    "                          input_shape= (256, 256, 3)))\n",
    "\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "model_eleven.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2- another convolution layer \n",
    "model_eleven.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 3- another max pool layer\n",
    "model_eleven.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 4- another convolution layer \n",
    "model_eleven.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 5- another max pool layer\n",
    "model_eleven.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 6- connect all nodes with dense layer\n",
    "model_eleven.add(Flatten())\n",
    "model_eleven.add(Dense(512, activation='relu'))\n",
    "model_eleven.add(layers.Dropout(0.2))\n",
    "\n",
    "# Layer 7- dense layer\n",
    "model_eleven.add(Dense(256, activation='relu'))\n",
    "model_eleven.add(layers.Dropout(0.2))\n",
    "\n",
    "# Layer 7- dense layer\n",
    "model_eleven.add(Dense(32, activation='relu'))\n",
    "model_eleven.add(layers.Dropout(0.2))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "model_eleven.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "model_eleven.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model_eleven.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-s8QFs45AzGD",
    "outputId": "ffc9ad88-29a0-4188-b890-4c04f9c047d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "148/148 [==============================] - 481s 3s/step - loss: 1.8579 - accuracy: 0.2936 - val_loss: 1.3696 - val_accuracy: 0.5048\n",
      "Epoch 2/50\n",
      "148/148 [==============================] - 473s 3s/step - loss: 1.3091 - accuracy: 0.5207 - val_loss: 0.9868 - val_accuracy: 0.6448\n",
      "Epoch 3/50\n",
      "148/148 [==============================] - 472s 3s/step - loss: 1.0152 - accuracy: 0.6411 - val_loss: 0.7357 - val_accuracy: 0.7396\n",
      "Epoch 4/50\n",
      "148/148 [==============================] - 473s 3s/step - loss: 0.8238 - accuracy: 0.7134 - val_loss: 0.7913 - val_accuracy: 0.7152\n",
      "Epoch 5/50\n",
      "148/148 [==============================] - 474s 3s/step - loss: 0.7157 - accuracy: 0.7537 - val_loss: 0.6792 - val_accuracy: 0.7663\n",
      "Epoch 6/50\n",
      "148/148 [==============================] - 474s 3s/step - loss: 0.5819 - accuracy: 0.8019 - val_loss: 0.6211 - val_accuracy: 0.7774\n",
      "Epoch 7/50\n",
      "148/148 [==============================] - 473s 3s/step - loss: 0.4969 - accuracy: 0.8327 - val_loss: 0.5706 - val_accuracy: 0.8015\n",
      "Epoch 8/50\n",
      "148/148 [==============================] - 476s 3s/step - loss: 0.4347 - accuracy: 0.8554 - val_loss: 0.6551 - val_accuracy: 0.7941\n",
      "Epoch 9/50\n",
      "148/148 [==============================] - 476s 3s/step - loss: 0.3379 - accuracy: 0.8905 - val_loss: 0.7957 - val_accuracy: 0.7400\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 2)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model_eleven_history = model_eleven.fit(train_generator, \n",
    "                                  epochs= 50, \n",
    "                                  validation_data = val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xosvYvU7AzGD",
    "outputId": "fcb2671d-bf78-479d-990b-8f61188e4050"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 35s 810ms/step - loss: 0.7885 - accuracy: 0.7443\n",
      "Test loss:  0.7884544134140015\n",
      "Test accuracy:  0.744259238243103\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = model_eleven.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpz05K2IBTHY"
   },
   "source": [
    "### Larger Models in Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzaB4iO5BOi1"
   },
   "source": [
    "Our next few models are quite large so we may be best served opening and running them in Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ut1t7hp9AzFp"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github//aokdata/Land_Cover_Classification/blob/main/Land_Cover_Classification_Notebook.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-aq_S-xdBjIz",
    "outputId": "69e10f87-7d01-4d30-e9ed-d623388e8558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#Mount Google Drive to access data\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlfsBAa8AzGD"
   },
   "source": [
    "### Model 12- Decreasing filter size over 4 Conv2D Layers and 5 Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWXCLV6zC0P3",
    "outputId": "aaf53f72-347c-4dcd-a4f6-ffef1231699d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18909 images belonging to 10 classes.\n",
      "Found 2701 images belonging to 10 classes.\n",
      "Found 5400 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#Import Data from Google Drive to use in Google Colab\n",
    "train_folder = '/content/drive/MyDrive/Data/Land_Cover_Classification_Project/data/split/train'\n",
    "test_folder = '/content/drive/MyDrive/Data/Land_Cover_Classification_Project/data/split/test'\n",
    "\n",
    "# Normalize images\n",
    "train_gen = ImageDataGenerator(rescale=1./255, validation_split = 0.125)\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#Import data as 70% Train (10% Validation of orginal data set) and 20% Test\n",
    "train_generator = train_gen.flow_from_directory(train_folder,\n",
    "                                                class_mode = 'categorical', \n",
    "                                                subset ='training', \n",
    "                                                batch_size=128,\n",
    "                                                shuffle=True,\n",
    "                                                seed=42)\n",
    "                                               \n",
    "val_generator= train_gen.flow_from_directory(train_folder,\n",
    "                                             class_mode= 'categorical',\n",
    "                                             subset = \"validation\",\n",
    "                                             batch_size=128,\n",
    "                                             shuffle=True,\n",
    "                                             seed=42)\n",
    "\n",
    "test_generator= test_gen.flow_from_directory(test_folder,\n",
    "                                              class_mode= 'categorical',\n",
    "                                              batch_size=128,\n",
    "                                              shuffle=False,\n",
    "                                              seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnkiQSqlAzGE",
    "outputId": "fb2c3a04-7af1-4060-aa5e-2582d7b31953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 128)     3584      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      73792     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               1606144   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,875,658\n",
      "Trainable params: 1,875,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate a Sequential model\n",
    "model_twelve = Sequential()\n",
    "\n",
    "\n",
    "# Input Layer- Convolution\n",
    "model_twelve.add(Conv2D(filters=128,\n",
    "                          kernel_size=(3, 3),\n",
    "                          activation='relu',\n",
    "                          input_shape= (256, 256, 3)))\n",
    "\n",
    "\n",
    "# Layer 1- max pool in 2x2 window\n",
    "model_twelve.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2- another convolution layer \n",
    "model_twelve.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 3- another max pool layer\n",
    "model_twelve.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 4- another convolution layer \n",
    "model_twelve.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 5- another max pool layer\n",
    "model_twelve.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 6- another convolution layer \n",
    "model_twelve.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "\n",
    "# Layer 7- another max pool layer\n",
    "model_twelve.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 8- connect all nodes with dense layer\n",
    "model_twelve.add(Flatten())\n",
    "model_twelve.add(Dense(512, activation='relu'))\n",
    "model_twelve.add(layers.Dropout(0.2))\n",
    "\n",
    "# Layer 9- dense layer\n",
    "model_twelve.add(Dense(256, activation='relu'))\n",
    "model_twelve.add(layers.Dropout(0.2))\n",
    "\n",
    "# Layer 10- dense layer\n",
    "model_twelve.add(Dense(128, activation='relu'))\n",
    "model_twelve.add(layers.Dropout(0.2))\n",
    "\n",
    "# Layer 11- dense layer\n",
    "model_twelve.add(Dense(32, activation='relu'))\n",
    "model_twelve.add(layers.Dropout(0.2))\n",
    "\n",
    "# Layer 12- dense layer\n",
    "model_twelve.add(Dense(16, activation='relu'))\n",
    "model_twelve.add(layers.Dropout(0.2))\n",
    "\n",
    "# Output Layer- softmax activiation for multi-categorical with 10 classes\n",
    "model_twelve.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the sequential CNN model- adam optimizer, \n",
    "# categorical_crossentropy loss, and set our metric to accuracy\n",
    "model_twelve.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model_twelve.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j2qfUYAAAzGE",
    "outputId": "6a95e91d-50fb-4d8a-bbd4-c4d0c54fac05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "148/148 [==============================] - 66s 386ms/step - loss: 2.0190 - accuracy: 0.2129 - val_loss: 1.7082 - val_accuracy: 0.2977\n",
      "Epoch 2/50\n",
      "148/148 [==============================] - 55s 374ms/step - loss: 1.6798 - accuracy: 0.3422 - val_loss: 1.3919 - val_accuracy: 0.4202\n",
      "Epoch 3/50\n",
      "148/148 [==============================] - 56s 375ms/step - loss: 1.4762 - accuracy: 0.3936 - val_loss: 1.2848 - val_accuracy: 0.4643\n",
      "Epoch 4/50\n",
      "148/148 [==============================] - 55s 373ms/step - loss: 1.3265 - accuracy: 0.4652 - val_loss: 1.1793 - val_accuracy: 0.5591\n",
      "Epoch 5/50\n",
      "148/148 [==============================] - 55s 373ms/step - loss: 1.1954 - accuracy: 0.5347 - val_loss: 1.0277 - val_accuracy: 0.6079\n",
      "Epoch 6/50\n",
      "148/148 [==============================] - 56s 375ms/step - loss: 1.0565 - accuracy: 0.6017 - val_loss: 1.1026 - val_accuracy: 0.6287\n",
      "Epoch 7/50\n",
      "148/148 [==============================] - 55s 372ms/step - loss: 0.9683 - accuracy: 0.6546 - val_loss: 0.8653 - val_accuracy: 0.7131\n",
      "Epoch 8/50\n",
      "148/148 [==============================] - 55s 374ms/step - loss: 0.8115 - accuracy: 0.7208 - val_loss: 0.8562 - val_accuracy: 0.7316\n",
      "Epoch 9/50\n",
      "148/148 [==============================] - 56s 376ms/step - loss: 0.7393 - accuracy: 0.7559 - val_loss: 0.7705 - val_accuracy: 0.7619\n",
      "Epoch 10/50\n",
      "148/148 [==============================] - 56s 376ms/step - loss: 0.6488 - accuracy: 0.7849 - val_loss: 0.7033 - val_accuracy: 0.7756\n",
      "Epoch 11/50\n",
      "148/148 [==============================] - 55s 372ms/step - loss: 0.5851 - accuracy: 0.8125 - val_loss: 0.7561 - val_accuracy: 0.7756\n",
      "Epoch 12/50\n",
      "148/148 [==============================] - 56s 376ms/step - loss: 0.5154 - accuracy: 0.8333 - val_loss: 0.6922 - val_accuracy: 0.7927\n",
      "Epoch 13/50\n",
      "148/148 [==============================] - 55s 374ms/step - loss: 0.4560 - accuracy: 0.8552 - val_loss: 0.6850 - val_accuracy: 0.8027\n",
      "Epoch 14/50\n",
      "148/148 [==============================] - 55s 373ms/step - loss: 0.4323 - accuracy: 0.8668 - val_loss: 0.6900 - val_accuracy: 0.7986\n",
      "Epoch 15/50\n",
      "148/148 [==============================] - 55s 375ms/step - loss: 0.3748 - accuracy: 0.8840 - val_loss: 0.7513 - val_accuracy: 0.7960\n",
      "Epoch 15: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 5)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model_twelve_history = model_twelve.fit(train_generator, \n",
    "                                  epochs= 50, \n",
    "                                  validation_data = val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ku1QqDIdAzGE",
    "outputId": "62e983b3-e4ff-4f99-ff76-2060c5ceac92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 14s 321ms/step - loss: 0.7148 - accuracy: 0.8069\n",
      "Test loss:  0.7148383855819702\n",
      "Test accuracy:  0.806851863861084\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = model_twelve.evaluate(test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sD9MvD2MAzGF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uvv7y-xAzGF"
   },
   "source": [
    "### Model 13- Transfer Learning: ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B0kvNWH-AzGF",
    "outputId": "f9187e14-a2a6-4b55-c0bc-ea49359b0cfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18909 images belonging to 10 classes.\n",
      "Found 2701 images belonging to 10 classes.\n",
      "Found 5400 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_folder = '/content/drive/MyDrive/Data/Land_Cover_Classification_Project/data/split/train'\n",
    "test_folder = '/content/drive/MyDrive/Data/Land_Cover_Classification_Project/data/split/test'\n",
    "\n",
    "# Normalize images\n",
    "train_gen = ImageDataGenerator(rescale=1./255, \n",
    "                               preprocessing_function = tf.keras.applications.resnet50.preprocess_input,\n",
    "                               validation_split = 0.125)\n",
    "test_gen = ImageDataGenerator(rescale=1./255, \n",
    "                              preprocessing_function = tf.keras.applications.resnet50.preprocess_input)\n",
    "\n",
    "#Import data as 70% Train (10% Validation of orginal data set) and 20% Test\n",
    "rn_train_generator = train_gen.flow_from_directory(train_folder,\n",
    "                                                class_mode = 'categorical', \n",
    "                                                subset ='training', \n",
    "                                                batch_size=128,\n",
    "                                                shuffle=True,\n",
    "                                                seed=42)\n",
    "                                               \n",
    "rn_val_generator= train_gen.flow_from_directory(train_folder,\n",
    "                                             class_mode= 'categorical',\n",
    "                                             subset = \"validation\",\n",
    "                                             batch_size=128,\n",
    "                                             shuffle=True,\n",
    "                                             seed=42)\n",
    "\n",
    "rn_test_generator= test_gen.flow_from_directory(test_folder,\n",
    "                                              class_mode= 'categorical',\n",
    "                                              batch_size=128,\n",
    "                                              shuffle=False,\n",
    "                                              seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6plgek1jAzGF",
    "outputId": "d31e3306-fb96-4be1-b75c-2113aa2d3850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Instantiate our Transfer Model Input Layer\n",
    "rn50 = ResNet50(weights='imagenet', \n",
    "                 include_top=False,\n",
    "                input_shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HoOw-QUuAzGG",
    "outputId": "3934f88f-248b-4c0f-f10e-9751ae59336e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 262, 262, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 128, 128, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 128, 128, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 128, 128, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 130, 130, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 64, 64, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 64, 64, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 64, 64, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 64, 64, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 32, 32, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 32, 32, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 32, 32, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 32, 32, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 16, 16, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 16, 16, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 16, 16, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 16, 16, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 16, 16, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 16, 16, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 8, 8, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 8, 8, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 8, 8, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 8, 8, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 8, 8, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 8, 8, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 8, 8, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 8, 8, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 8, 8, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 8, 8, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Check to ensure there is no prediction layer\n",
    "rn50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNhh3jmfAzGG"
   },
   "outputs": [],
   "source": [
    "#Instantiate a Sequential model\n",
    "rn50_model = Sequential()\n",
    "\n",
    "#Input Layer\n",
    "rn50_model.add(rn50)\n",
    "\n",
    "rn50_model.add(layers.Flatten())\n",
    "\n",
    "#Add Dense Layer\n",
    "rn50_model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "#Output Layer\n",
    "rn50_model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2VYCAwzwAzGG",
    "outputId": "5c82a66d-dca5-4e71-997c-46b181588044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 True\n",
      "flatten True\n",
      "dense True\n",
      "dense_1 True\n",
      "216\n"
     ]
    }
   ],
   "source": [
    "# Check whether a layer is trainable (or alter its setting) through the layer.trainable attribute\n",
    "for layer in rn50_model.layers:\n",
    "    print(layer.name, layer.trainable)\n",
    "    \n",
    "# Similarly, you can check how many trainable weights are in the model\n",
    "print(len(rn50_model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-re4Tc-AzGG",
    "outputId": "54b85e8d-3308-421c-e421-a6fd364c2a13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 False\n",
      "flatten True\n",
      "dense True\n",
      "dense_1 True\n"
     ]
    }
   ],
   "source": [
    "# Freeze our RN50 Layer\n",
    "rn50.trainable = False\n",
    "\n",
    "# Sanity Check that RN50 layer is frozen\n",
    "for layer in rn50_model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gbHcmiwYAzGG",
    "outputId": "bed4f156-e2b5-4b1b-a355-54878887a3db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 131072)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8388672   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,977,034\n",
      "Trainable params: 8,389,322\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Compile the model- adam optimizer, categorical_crossentropy loss, and set our metric to accuracy\n",
    "rn50_model.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "rn50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7EhGd-7bAzGH",
    "outputId": "a4387433-1288-4b4f-d688-006a52dfb713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "148/148 [==============================] - 3674s 25s/step - loss: 2.7104 - accuracy: 0.1414 - val_loss: 2.0903 - val_accuracy: 0.2177\n",
      "Epoch 2/50\n",
      "148/148 [==============================] - 68s 461ms/step - loss: 2.0713 - accuracy: 0.2222 - val_loss: 2.0561 - val_accuracy: 0.2307\n",
      "Epoch 3/50\n",
      "148/148 [==============================] - 69s 463ms/step - loss: 2.0331 - accuracy: 0.2361 - val_loss: 2.0107 - val_accuracy: 0.2403\n",
      "Epoch 4/50\n",
      "148/148 [==============================] - 68s 462ms/step - loss: 2.0083 - accuracy: 0.2370 - val_loss: 1.9929 - val_accuracy: 0.2418\n",
      "Epoch 5/50\n",
      "148/148 [==============================] - 68s 460ms/step - loss: 1.9802 - accuracy: 0.2465 - val_loss: 1.9474 - val_accuracy: 0.2725\n",
      "Epoch 6/50\n",
      "148/148 [==============================] - 68s 459ms/step - loss: 1.9423 - accuracy: 0.2570 - val_loss: 1.9547 - val_accuracy: 0.2403\n",
      "Epoch 7/50\n",
      "148/148 [==============================] - 68s 461ms/step - loss: 1.9135 - accuracy: 0.2568 - val_loss: 1.8815 - val_accuracy: 0.2743\n",
      "Epoch 8/50\n",
      "148/148 [==============================] - 69s 463ms/step - loss: 1.8837 - accuracy: 0.2705 - val_loss: 1.8668 - val_accuracy: 0.2929\n",
      "Epoch 9/50\n",
      "148/148 [==============================] - 68s 461ms/step - loss: 1.8704 - accuracy: 0.2720 - val_loss: 1.8368 - val_accuracy: 0.2951\n",
      "Epoch 10/50\n",
      "148/148 [==============================] - 68s 458ms/step - loss: 1.8393 - accuracy: 0.2836 - val_loss: 1.8173 - val_accuracy: 0.2914\n",
      "Epoch 11/50\n",
      "148/148 [==============================] - 68s 461ms/step - loss: 1.8120 - accuracy: 0.2904 - val_loss: 1.7950 - val_accuracy: 0.2995\n",
      "Epoch 12/50\n",
      "148/148 [==============================] - 68s 457ms/step - loss: 1.8245 - accuracy: 0.2773 - val_loss: 1.8384 - val_accuracy: 0.2558\n",
      "Epoch 13/50\n",
      "148/148 [==============================] - 68s 457ms/step - loss: 1.7899 - accuracy: 0.2879 - val_loss: 1.7876 - val_accuracy: 0.2817\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = [EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 2), \n",
    "               ModelCheckpoint(filepath='rn50_model.h5', monitor='val_accuracy', save_best_only=True)]\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "rn50_model_history = rn50_model.fit(rn_train_generator, \n",
    "                                  epochs= 50, \n",
    "                                  validation_data = rn_val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-yBPiHb-AzGR",
    "outputId": "85851da8-48c0-4eb5-f371-51608bb52b18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 950s 23s/step - loss: 1.7919 - accuracy: 0.2861\n",
      "Test loss:  1.7918556928634644\n",
      "Test accuracy:  0.28611111640930176\n"
     ]
    }
   ],
   "source": [
    "#Check loss and accuracy on test data\n",
    "test_loss, test_acc = rn50_model.evaluate(rn_test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ti_w0xD2AzGR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mrRj_ZHAzGR"
   },
   "source": [
    "### Model 14- Transfer Learning: VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4P5nH1fNAzGS",
    "outputId": "2dd489d5-4259-4979-fb08-1a90837b384f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18909 images belonging to 10 classes.\n",
      "Found 2701 images belonging to 10 classes.\n",
      "Found 5400 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_folder = '/content/drive/MyDrive/Data/Land_Cover_Classification_Project/data/split/train'\n",
    "test_folder = '/content/drive/MyDrive/Data/Land_Cover_Classification_Project/data/split/test'\n",
    "\n",
    "# Normalize images\n",
    "train_gen = ImageDataGenerator(rescale=1./255, \n",
    "                               preprocessing_function = tf.keras.applications.vgg19.preprocess_input,\n",
    "                               validation_split = 0.125)\n",
    "test_gen = ImageDataGenerator(rescale=1./255, \n",
    "                              preprocessing_function = tf.keras.applications.vgg19.preprocess_input)\n",
    "\n",
    "#Import data as 70% Train (10% Validation of orginal data set) and 20% Test\n",
    "vgg_train_generator = train_gen.flow_from_directory(train_folder,\n",
    "                                                class_mode = 'categorical', \n",
    "                                                subset ='training', \n",
    "                                                batch_size=128,\n",
    "                                                shuffle=True,\n",
    "                                                seed=42)\n",
    "                                               \n",
    "vgg_val_generator= train_gen.flow_from_directory(train_folder,\n",
    "                                             class_mode= 'categorical',\n",
    "                                             subset = \"validation\",\n",
    "                                             batch_size=128,\n",
    "                                             shuffle=True,\n",
    "                                             seed=42)\n",
    "\n",
    "vgg_test_generator= test_gen.flow_from_directory(test_folder,\n",
    "                                              class_mode= 'categorical',\n",
    "                                              batch_size=128,\n",
    "                                              shuffle=False,\n",
    "                                              seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aw5iBRHIAzGS",
    "outputId": "44656281-4bb0-4133-f43b-9f21c972ef83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#Reshape our input\n",
    "vgg19 = VGG19(weights='imagenet', \n",
    "              include_top=False, \n",
    "              input_shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSpv7I9_AzGS",
    "outputId": "bab245ea-38c6-4a04-9692-7ace04f0819e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Check to ensure there is no prediction layer\n",
    "vgg19.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8ckXMWXAzGS"
   },
   "outputs": [],
   "source": [
    "#Instantiate a Sequential model\n",
    "vgg_model = Sequential()\n",
    "\n",
    "#Input Layer\n",
    "# vgg_model.add(vgg)\n",
    "vgg_model.add(vgg19)\n",
    "\n",
    "vgg_model.add(layers.Flatten())\n",
    "\n",
    "#Add Dense Layer\n",
    "vgg_model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "#Output Layer\n",
    "vgg_model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q9AodJqpAzGW",
    "outputId": "b37839a1-5705-4b0f-84b3-356af7e7aaa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg19 True\n",
      "flatten_1 True\n",
      "dense_2 True\n",
      "dense_3 True\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "# Check whether a layer is trainable (or alter its setting) through the layer.trainable attribute\n",
    "for layer in vgg_model.layers:\n",
    "    print(layer.name, layer.trainable)\n",
    "    \n",
    "# Similarly, you can check how many trainable weights are in the model\n",
    "print(len(vgg_model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f47SHT_AzGW",
    "outputId": "7ed04b92-ede3-401e-de5c-0dd7cd50736c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg19 False\n",
      "flatten_1 True\n",
      "dense_2 True\n",
      "dense_3 True\n"
     ]
    }
   ],
   "source": [
    "#Freeze our VGG19 Layer\n",
    "vgg19.trainable = False\n",
    "\n",
    "#Sanity check that VGG19 Layer is frozen\n",
    "for layer in vgg_model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gu-RT8bkAzGW",
    "outputId": "ea3052d4-de88-47df-ff6c-d57e09a9f5e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 8, 8, 512)         20024384  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                2097216   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,122,250\n",
      "Trainable params: 2,097,866\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Compile the model- adam optimizer, categorical_crossentropy loss, and set our metric to accuracy\n",
    "vgg_model.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDvg4dSOAzGW",
    "outputId": "c8105df0-2d87-48db-df26-941e73d19dbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "148/148 [==============================] - 77s 483ms/step - loss: 1.3647 - accuracy: 0.5560 - val_loss: 0.8784 - val_accuracy: 0.7116\n",
      "Epoch 2/50\n",
      "148/148 [==============================] - 68s 458ms/step - loss: 0.7692 - accuracy: 0.7433 - val_loss: 0.7042 - val_accuracy: 0.7582\n",
      "Epoch 3/50\n",
      "148/148 [==============================] - 68s 458ms/step - loss: 0.6222 - accuracy: 0.7888 - val_loss: 0.6486 - val_accuracy: 0.7756\n",
      "Epoch 4/50\n",
      "148/148 [==============================] - 68s 457ms/step - loss: 0.5468 - accuracy: 0.8129 - val_loss: 0.6318 - val_accuracy: 0.7816\n",
      "Epoch 5/50\n",
      "148/148 [==============================] - 68s 460ms/step - loss: 0.4730 - accuracy: 0.8388 - val_loss: 0.6117 - val_accuracy: 0.7923\n",
      "Epoch 6/50\n",
      "148/148 [==============================] - 68s 460ms/step - loss: 0.4401 - accuracy: 0.8512 - val_loss: 0.5157 - val_accuracy: 0.8130\n",
      "Epoch 7/50\n",
      "148/148 [==============================] - 68s 460ms/step - loss: 0.3914 - accuracy: 0.8692 - val_loss: 0.5857 - val_accuracy: 0.8034\n",
      "Epoch 8/50\n",
      "148/148 [==============================] - 68s 460ms/step - loss: 0.3659 - accuracy: 0.8762 - val_loss: 0.5061 - val_accuracy: 0.8160\n",
      "Epoch 9/50\n",
      "148/148 [==============================] - 68s 461ms/step - loss: 0.3392 - accuracy: 0.8861 - val_loss: 0.4923 - val_accuracy: 0.8278\n",
      "Epoch 10/50\n",
      "148/148 [==============================] - 68s 462ms/step - loss: 0.3179 - accuracy: 0.8950 - val_loss: 0.4970 - val_accuracy: 0.8319\n",
      "Epoch 11/50\n",
      "148/148 [==============================] - 68s 458ms/step - loss: 0.3194 - accuracy: 0.8934 - val_loss: 0.5266 - val_accuracy: 0.8186\n",
      "Epoch 12/50\n",
      "148/148 [==============================] - 68s 459ms/step - loss: 0.2904 - accuracy: 0.9036 - val_loss: 0.5097 - val_accuracy: 0.8334\n",
      "Epoch 13/50\n",
      "148/148 [==============================] - 68s 459ms/step - loss: 0.2674 - accuracy: 0.9126 - val_loss: 0.5046 - val_accuracy: 0.8193\n",
      "Epoch 14/50\n",
      "148/148 [==============================] - 68s 460ms/step - loss: 0.2558 - accuracy: 0.9161 - val_loss: 0.4686 - val_accuracy: 0.8401\n",
      "Epoch 15/50\n",
      "148/148 [==============================] - 68s 460ms/step - loss: 0.2409 - accuracy: 0.9243 - val_loss: 0.4917 - val_accuracy: 0.8323\n",
      "Epoch 16/50\n",
      "148/148 [==============================] - 68s 456ms/step - loss: 0.2275 - accuracy: 0.9269 - val_loss: 0.4826 - val_accuracy: 0.8330\n",
      "Epoch 16: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = [EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 5), \n",
    "               ModelCheckpoint(filepath='/content/drive/MyDrive/Data/Land_Cover_Classification_Project/vgg19_model.h5', \n",
    "                               monitor='val_accuracy', \n",
    "                               save_best_only=True, \n",
    "                               mode='max')]\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "vgg_model_history = vgg_model.fit(vgg_train_generator, \n",
    "                                  epochs= 50, \n",
    "                                  validation_data = vgg_val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ee2jpdBPAzGa",
    "outputId": "92065830-2d02-47f8-d3b2-3717daff1728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 18s 409ms/step - loss: 0.4333 - accuracy: 0.8570\n",
      "Test loss:  0.43328657746315\n",
      "Test accuracy:  0.8570370078086853\n"
     ]
    }
   ],
   "source": [
    "# Check loss and accuracy on test data\n",
    "test_loss, test_acc = vgg_model.evaluate(vgg_test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K25_JB9MAzGb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QimTGtyCAzGb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qk5hLTnbhXzg"
   },
   "source": [
    "### Model 14- Transfer Learning: VGG19 with added Dense and Dropout Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcvWGmSJAGmI"
   },
   "source": [
    "Using the same data input and VGG19 model as Model 13 but with two Dense Layers each with a 0.2 Dropout Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Qn1RK_ywhY99"
   },
   "outputs": [],
   "source": [
    "#Instantiate a Sequential model\n",
    "vgg2_model = Sequential()\n",
    "\n",
    "#Input Layer\n",
    "vgg2_model.add(vgg19)\n",
    "\n",
    "vgg2_model.add(layers.Flatten())\n",
    "\n",
    "#Add Dense Layer\n",
    "vgg2_model.add(layers.Dense(512, activation='relu'))\n",
    "vgg2_model.add(layers.Dropout(0.2))\n",
    "\n",
    "#Add Dense Layer\n",
    "vgg2_model.add(layers.Dense(64, activation='relu'))\n",
    "vgg2_model.add(layers.Dropout(0.2))\n",
    "\n",
    "#Output Layer\n",
    "vgg2_model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CmzHRdLShZBl",
    "outputId": "624cf6ea-eca8-4d7e-88a0-eec0be3f7d0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg19 False\n",
      "flatten True\n",
      "dense True\n",
      "dropout True\n",
      "dense_1 True\n",
      "dropout_1 True\n",
      "dense_2 True\n"
     ]
    }
   ],
   "source": [
    "#Freeze our VGG19 Layer\n",
    "vgg19.trainable = False\n",
    "\n",
    "#Sanity check that VGG19 Layer is frozen\n",
    "for layer in vgg2_model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U0PyHY9BhZIL",
    "outputId": "d8b76f8d-2b93-4f83-f5ee-fc0757e94cef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 8, 8, 512)         20024384  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               16777728  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,835,594\n",
      "Trainable params: 16,811,210\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Compile the model- adam optimizer, categorical_crossentropy loss, and set our metric to accuracy\n",
    "vgg2_model.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "vgg2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6FobtchhZLo",
    "outputId": "b35403e4-94e3-4b4d-8af5-d6c72b677cc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "148/148 [==============================] - 7391s 50s/step - loss: 1.8231 - accuracy: 0.3587 - val_loss: 1.1090 - val_accuracy: 0.6342\n",
      "Epoch 2/50\n",
      "148/148 [==============================] - 71s 477ms/step - loss: 1.0250 - accuracy: 0.6353 - val_loss: 0.7836 - val_accuracy: 0.7212\n",
      "Epoch 3/50\n",
      "148/148 [==============================] - 68s 458ms/step - loss: 0.8505 - accuracy: 0.7015 - val_loss: 0.8172 - val_accuracy: 0.7212\n",
      "Epoch 4/50\n",
      "148/148 [==============================] - 70s 470ms/step - loss: 0.7852 - accuracy: 0.7258 - val_loss: 0.6257 - val_accuracy: 0.7719\n",
      "Epoch 5/50\n",
      "148/148 [==============================] - 71s 476ms/step - loss: 0.7094 - accuracy: 0.7488 - val_loss: 0.6506 - val_accuracy: 0.7775\n",
      "Epoch 6/50\n",
      "148/148 [==============================] - 71s 476ms/step - loss: 0.6755 - accuracy: 0.7652 - val_loss: 0.5656 - val_accuracy: 0.7967\n",
      "Epoch 7/50\n",
      "148/148 [==============================] - 68s 456ms/step - loss: 0.6507 - accuracy: 0.7722 - val_loss: 0.6156 - val_accuracy: 0.7830\n",
      "Epoch 8/50\n",
      "148/148 [==============================] - 68s 456ms/step - loss: 0.6376 - accuracy: 0.7757 - val_loss: 0.5582 - val_accuracy: 0.7949\n",
      "Epoch 9/50\n",
      "148/148 [==============================] - 70s 473ms/step - loss: 0.6022 - accuracy: 0.7889 - val_loss: 0.5788 - val_accuracy: 0.7990\n",
      "Epoch 10/50\n",
      "148/148 [==============================] - 68s 455ms/step - loss: 0.5796 - accuracy: 0.7971 - val_loss: 0.5911 - val_accuracy: 0.7942\n",
      "Epoch 11/50\n",
      "148/148 [==============================] - 71s 478ms/step - loss: 0.5973 - accuracy: 0.7893 - val_loss: 0.5454 - val_accuracy: 0.8156\n",
      "Epoch 12/50\n",
      "148/148 [==============================] - 68s 457ms/step - loss: 0.5398 - accuracy: 0.8083 - val_loss: 0.5916 - val_accuracy: 0.7964\n",
      "Epoch 13/50\n",
      "148/148 [==============================] - 70s 473ms/step - loss: 0.5536 - accuracy: 0.8065 - val_loss: 0.5270 - val_accuracy: 0.8212\n",
      "Epoch 14/50\n",
      "148/148 [==============================] - 68s 456ms/step - loss: 0.5201 - accuracy: 0.8206 - val_loss: 0.5763 - val_accuracy: 0.7971\n",
      "Epoch 15/50\n",
      "148/148 [==============================] - 68s 457ms/step - loss: 0.4856 - accuracy: 0.8303 - val_loss: 0.5492 - val_accuracy: 0.8130\n",
      "Epoch 16/50\n",
      "148/148 [==============================] - 67s 454ms/step - loss: 0.4797 - accuracy: 0.8303 - val_loss: 0.5361 - val_accuracy: 0.8201\n",
      "Epoch 17/50\n",
      "148/148 [==============================] - 68s 456ms/step - loss: 0.5334 - accuracy: 0.8137 - val_loss: 0.5761 - val_accuracy: 0.8064\n",
      "Epoch 18/50\n",
      "148/148 [==============================] - 68s 456ms/step - loss: 0.5072 - accuracy: 0.8255 - val_loss: 0.5535 - val_accuracy: 0.8119\n",
      "Epoch 18: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = [EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 5), \n",
    "               ModelCheckpoint(filepath='/content/drive/MyDrive/Data/Land_Cover_Classification_Project/vgg2_model.h5', \n",
    "                               monitor='val_accuracy', \n",
    "                               save_best_only=True, \n",
    "                               mode='max')]\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "vgg2_model_history = vgg2_model.fit(vgg_train_generator, \n",
    "                                  epochs= 50, \n",
    "                                  validation_data = vgg_val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dee2hscHhZOj",
    "outputId": "dbba47bd-4ca7-4728-aad0-65e0401ed6c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 1876s 45s/step - loss: 0.5056 - accuracy: 0.8309\n",
      "Test loss:  0.505621612071991\n",
      "Test accuracy:  0.8309259414672852\n"
     ]
    }
   ],
   "source": [
    "# Check loss and accuracy on test data\n",
    "test_loss, test_acc = vgg2_model.evaluate(vgg_test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8orbEr3_9t_"
   },
   "source": [
    "### Model 15- Transfer Learning: VGG19 with Augmentation and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQqGzOCY_-Bb"
   },
   "source": [
    "Adding additional images to train on through augmentation and additional dense and dropout layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8sP-WjzAzGb",
    "outputId": "a14f0262-0fe9-4dec-d735-0995096f068d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18909 images belonging to 10 classes.\n",
      "Found 2701 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add augmentation (horizontal and vertical flips) to training data but not validation data.\n",
    "\n",
    "train_folder = '/content/drive/MyDrive/Data/Land_Cover_Classification_Project/data/split/train'\n",
    "\n",
    "\n",
    "# Normalize images and Augment with Horizontal and Vertical Flips\n",
    "aug_train_gen = ImageDataGenerator(rescale=1./255, \n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=True,\n",
    "                               validation_split = 0.125, \n",
    "                               preprocessing_function = tf.keras.applications.vgg19.preprocess_input)\n",
    "\n",
    "aug_val_gen = ImageDataGenerator(rescale=1./255, \n",
    "                                 validation_split = 0.125, \n",
    "                                 preprocessing_function = tf.keras.applications.vgg19.preprocess_input)\n",
    "\n",
    "\n",
    "#Augment the train data\n",
    "aug_train_generator = aug_train_gen.flow_from_directory(train_folder,\n",
    "                                                class_mode = 'categorical', \n",
    "                                                subset ='training', \n",
    "                                                batch_size=128,\n",
    "                                                shuffle=False,\n",
    "                                                seed=42)\n",
    "                                               \n",
    "aug_val_generator= aug_val_gen.flow_from_directory(train_folder,\n",
    "                                                   class_mode= 'categorical',\n",
    "                                                   subset = \"validation\",\n",
    "                                                   batch_size=128,\n",
    "                                                   shuffle=False,\n",
    "                                                   seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0yJi_1C_-yA1",
    "outputId": "95b4c908-5854-4fe9-9f63-01890bbc9710"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#Reshape our input\n",
    "vgg19 = VGG19(weights='imagenet', \n",
    "              include_top=False, \n",
    "              input_shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DmFA4-LA-y7L",
    "outputId": "ed6a6f83-77a9-47c8-837f-5ee77d538c9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Check to ensure there is no prediction layer\n",
    "vgg19.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38McZMdR-zAN"
   },
   "outputs": [],
   "source": [
    "#Instantiate a Sequential model\n",
    "aug_vgg_model = Sequential()\n",
    "\n",
    "#Input Layer\n",
    "aug_vgg_model.add(vgg19)\n",
    "\n",
    "aug_vgg_model.add(layers.Flatten())\n",
    "\n",
    "#Add Dense Layer\n",
    "aug_vgg_model.add(layers.Dense(512, activation='relu'))\n",
    "aug_vgg_model.add(layers.Dropout(0.2))\n",
    "\n",
    "#Add Dense Layer\n",
    "aug_vgg_model.add(layers.Dense(256, activation='relu'))\n",
    "aug_vgg_model.add(layers.Dropout(0.2))\n",
    "\n",
    "#Add Dense Layer\n",
    "aug_vgg_model.add(layers.Dense(128, activation='relu'))\n",
    "aug_vgg_model.add(layers.Dropout(0.2))\n",
    "\n",
    "#Add Dense Layer\n",
    "aug_vgg_model.add(layers.Dense(64, activation='relu'))\n",
    "aug_vgg_model.add(layers.Dropout(0.2))\n",
    "\n",
    "#Add Dense Layer\n",
    "aug_vgg_model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "#Output Layer\n",
    "aug_vgg_model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Vgo0cUP-zD8",
    "outputId": "9880803a-5f13-4d12-842e-e164a4d0da15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg19 True\n",
      "flatten True\n",
      "dense True\n",
      "dropout True\n",
      "dense_1 True\n",
      "dropout_1 True\n",
      "dense_2 True\n",
      "dropout_2 True\n",
      "dense_3 True\n",
      "dropout_3 True\n",
      "dense_4 True\n",
      "dense_5 True\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "# Check whether a layer is trainable (or alter its setting) through the layer.trainable attribute\n",
    "for layer in aug_vgg_model.layers:\n",
    "    print(layer.name, layer.trainable)\n",
    "    \n",
    "# Similarly, you can check how many trainable weights are in the model\n",
    "print(len(aug_vgg_model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bpJdhEOo-zJH",
    "outputId": "5867ac4e-f7ca-49fe-f70a-51f0623e387d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg19 False\n",
      "flatten True\n",
      "dense True\n",
      "dropout True\n",
      "dense_1 True\n",
      "dropout_1 True\n",
      "dense_2 True\n",
      "dropout_2 True\n",
      "dense_3 True\n",
      "dropout_3 True\n",
      "dense_4 True\n",
      "dense_5 True\n"
     ]
    }
   ],
   "source": [
    "#Freeze our VGG19 Layer\n",
    "vgg19.trainable = False\n",
    "\n",
    "#Sanity check that VGG19 Layer is frozen\n",
    "for layer in aug_vgg_model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdRoQR5b-zOr",
    "outputId": "ba7fc377-7fe7-49ae-8c5d-cd083052a0ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 8, 8, 512)         20024384  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               16777728  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,977,002\n",
      "Trainable params: 16,952,618\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Compile the model- adam optimizer, categorical_crossentropy loss, and set our metric to accuracy\n",
    "aug_vgg_model.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "aug_vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-iroh06-zTN",
    "outputId": "2c40d2e3-4522-453c-cdbb-4a3192872297"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "148/148 [==============================] - 4033s 27s/step - loss: 2.4683 - accuracy: 0.1145 - val_loss: 2.1912 - val_accuracy: 0.2125\n",
      "Epoch 2/50\n",
      "148/148 [==============================] - 67s 452ms/step - loss: 2.1773 - accuracy: 0.1759 - val_loss: 2.2147 - val_accuracy: 0.2518\n",
      "Epoch 3/50\n",
      "148/148 [==============================] - 65s 435ms/step - loss: 2.1135 - accuracy: 0.2230 - val_loss: 2.1316 - val_accuracy: 0.2251\n",
      "Epoch 4/50\n",
      "148/148 [==============================] - 67s 454ms/step - loss: 2.0631 - accuracy: 0.2228 - val_loss: 1.9457 - val_accuracy: 0.2529\n",
      "Epoch 5/50\n",
      "148/148 [==============================] - 68s 455ms/step - loss: 1.8891 - accuracy: 0.2583 - val_loss: 1.7734 - val_accuracy: 0.3750\n",
      "Epoch 6/50\n",
      "148/148 [==============================] - 65s 435ms/step - loss: 1.8275 - accuracy: 0.3054 - val_loss: 1.6181 - val_accuracy: 0.3165\n",
      "Epoch 7/50\n",
      "148/148 [==============================] - 67s 451ms/step - loss: 1.8027 - accuracy: 0.2902 - val_loss: 1.6009 - val_accuracy: 0.4310\n",
      "Epoch 8/50\n",
      "148/148 [==============================] - 65s 436ms/step - loss: 1.7047 - accuracy: 0.3412 - val_loss: 1.4837 - val_accuracy: 0.4284\n",
      "Epoch 9/50\n",
      "148/148 [==============================] - 66s 448ms/step - loss: 1.6826 - accuracy: 0.3634 - val_loss: 1.4805 - val_accuracy: 0.4654\n",
      "Epoch 10/50\n",
      "148/148 [==============================] - 67s 454ms/step - loss: 1.6289 - accuracy: 0.3944 - val_loss: 1.4898 - val_accuracy: 0.4683\n",
      "Epoch 11/50\n",
      "148/148 [==============================] - 64s 433ms/step - loss: 1.6040 - accuracy: 0.3866 - val_loss: 1.4064 - val_accuracy: 0.4654\n",
      "Epoch 12/50\n",
      "148/148 [==============================] - 64s 435ms/step - loss: 1.5536 - accuracy: 0.3980 - val_loss: 1.4072 - val_accuracy: 0.4561\n",
      "Epoch 13/50\n",
      "148/148 [==============================] - 67s 454ms/step - loss: 1.5452 - accuracy: 0.3930 - val_loss: 1.3648 - val_accuracy: 0.4750\n",
      "Epoch 14/50\n",
      "148/148 [==============================] - 67s 451ms/step - loss: 1.4794 - accuracy: 0.4136 - val_loss: 1.3372 - val_accuracy: 0.4861\n",
      "Epoch 15/50\n",
      "148/148 [==============================] - 67s 451ms/step - loss: 1.5183 - accuracy: 0.4124 - val_loss: 1.3653 - val_accuracy: 0.5050\n",
      "Epoch 16/50\n",
      "148/148 [==============================] - 67s 453ms/step - loss: 1.5151 - accuracy: 0.4348 - val_loss: 1.2526 - val_accuracy: 0.5305\n",
      "Epoch 17/50\n",
      "148/148 [==============================] - 65s 436ms/step - loss: 1.4658 - accuracy: 0.4110 - val_loss: 1.2804 - val_accuracy: 0.5120\n",
      "Epoch 18/50\n",
      "148/148 [==============================] - 66s 448ms/step - loss: 1.4752 - accuracy: 0.4128 - val_loss: 1.2525 - val_accuracy: 0.5524\n",
      "Epoch 19/50\n",
      "148/148 [==============================] - 64s 434ms/step - loss: 1.4468 - accuracy: 0.4454 - val_loss: 1.2845 - val_accuracy: 0.5354\n",
      "Epoch 20/50\n",
      "148/148 [==============================] - 65s 436ms/step - loss: 1.4595 - accuracy: 0.4283 - val_loss: 1.2861 - val_accuracy: 0.5246\n",
      "Epoch 21/50\n",
      "148/148 [==============================] - 64s 434ms/step - loss: 1.4350 - accuracy: 0.4468 - val_loss: 1.2683 - val_accuracy: 0.5420\n",
      "Epoch 22/50\n",
      "148/148 [==============================] - 64s 434ms/step - loss: 1.4268 - accuracy: 0.4540 - val_loss: 1.2199 - val_accuracy: 0.5361\n",
      "Epoch 23/50\n",
      "148/148 [==============================] - 67s 453ms/step - loss: 1.3640 - accuracy: 0.4600 - val_loss: 1.2746 - val_accuracy: 0.5646\n",
      "Epoch 24/50\n",
      "148/148 [==============================] - 64s 433ms/step - loss: 1.3972 - accuracy: 0.4775 - val_loss: 1.2285 - val_accuracy: 0.5405\n",
      "Epoch 25/50\n",
      "148/148 [==============================] - 64s 433ms/step - loss: 1.3656 - accuracy: 0.4937 - val_loss: 1.1499 - val_accuracy: 0.5476\n",
      "Epoch 26/50\n",
      "148/148 [==============================] - 67s 454ms/step - loss: 1.3322 - accuracy: 0.5058 - val_loss: 1.1110 - val_accuracy: 0.6224\n",
      "Epoch 27/50\n",
      "148/148 [==============================] - 65s 435ms/step - loss: 1.3772 - accuracy: 0.4971 - val_loss: 1.1192 - val_accuracy: 0.6168\n",
      "Epoch 28/50\n",
      "148/148 [==============================] - 64s 434ms/step - loss: 1.4133 - accuracy: 0.4799 - val_loss: 1.1677 - val_accuracy: 0.6013\n",
      "Epoch 29/50\n",
      "148/148 [==============================] - 67s 455ms/step - loss: 1.3065 - accuracy: 0.5246 - val_loss: 1.0822 - val_accuracy: 0.6390\n",
      "Epoch 30/50\n",
      "148/148 [==============================] - 64s 433ms/step - loss: 1.3355 - accuracy: 0.5152 - val_loss: 1.2733 - val_accuracy: 0.5553\n",
      "Epoch 31/50\n",
      "148/148 [==============================] - 64s 434ms/step - loss: 1.3202 - accuracy: 0.5199 - val_loss: 1.2862 - val_accuracy: 0.5331\n",
      "Epoch 32/50\n",
      "148/148 [==============================] - 64s 435ms/step - loss: 1.3994 - accuracy: 0.4692 - val_loss: 1.3445 - val_accuracy: 0.5313\n",
      "Epoch 33/50\n",
      "148/148 [==============================] - 64s 433ms/step - loss: 1.3605 - accuracy: 0.4693 - val_loss: 1.1464 - val_accuracy: 0.5939\n",
      "Epoch 34/50\n",
      "148/148 [==============================] - 64s 434ms/step - loss: 1.3081 - accuracy: 0.5159 - val_loss: 1.2755 - val_accuracy: 0.5320\n",
      "Epoch 34: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "\n",
    "valcallback = [EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 5), \n",
    "               ModelCheckpoint(filepath='/content/drive/MyDrive/Data/Land_Cover_Classification_Project/aug_vgg19_model.h5', \n",
    "                               monitor='val_accuracy', \n",
    "                               save_best_only=True, \n",
    "                               mode='max')]\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "aug_vgg_model_history = aug_vgg_model.fit(aug_train_generator, \n",
    "                                  epochs= 50, \n",
    "                                  validation_data = aug_val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vyIRJ27M-zbB",
    "outputId": "f42a7e8e-7fbf-4e51-8562-c1dee3cfe2a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 1023s 24s/step - loss: 1.2468 - accuracy: 0.5502\n",
      "Test loss:  1.2468000650405884\n",
      "Test accuracy:  0.5501852035522461\n"
     ]
    }
   ],
   "source": [
    "# Check loss and accuracy on test data\n",
    "test_loss, test_acc = aug_vgg_model.evaluate(vgg_test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNAGeBBy_Qf_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqG3WuJw-q6j"
   },
   "source": [
    "### Model 15- Transfer Learning: VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEIuMF_b-rPp"
   },
   "source": [
    "Simple VGG16 model with 2 Dense and Dropout Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_DBVK7bI_QvS",
    "outputId": "70c9646f-d31e-407f-9ce1-3a9fe6b1c0ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18909 images belonging to 10 classes.\n",
      "Found 2701 images belonging to 10 classes.\n",
      "Found 5400 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_folder = '/content/drive/MyDrive/Data/Land_Cover_Classification_Project/data/split/train'\n",
    "test_folder = '/content/drive/MyDrive/Data/Land_Cover_Classification_Project/data/split/test'\n",
    "\n",
    "# Normalize images\n",
    "train16_gen = ImageDataGenerator(rescale=1./255, \n",
    "                               preprocessing_function = tf.keras.applications.vgg16.preprocess_input,\n",
    "                               validation_split = 0.125)\n",
    "test16_gen = ImageDataGenerator(rescale=1./255, \n",
    "                              preprocessing_function = tf.keras.applications.vgg16.preprocess_input)\n",
    "\n",
    "#Import data as 70% Train (10% Validation of orginal data set) and 20% Test\n",
    "vgg16_train_generator = train16_gen.flow_from_directory(train_folder,\n",
    "                                                class_mode = 'categorical', \n",
    "                                                subset ='training', \n",
    "                                                batch_size=128,\n",
    "                                                shuffle=True,\n",
    "                                                seed=42)\n",
    "                                               \n",
    "vgg16_val_generator= train16_gen.flow_from_directory(train_folder,\n",
    "                                             class_mode= 'categorical',\n",
    "                                             subset = \"validation\",\n",
    "                                             batch_size=128,\n",
    "                                             shuffle=True,\n",
    "                                             seed=42)\n",
    "\n",
    "vgg16_test_generator= test16_gen.flow_from_directory(test_folder,\n",
    "                                              class_mode= 'categorical',\n",
    "                                              batch_size=128,\n",
    "                                              shuffle=False,\n",
    "                                              seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aj6OfquoAeUx",
    "outputId": "47c248c7-2ce9-4948-937f-d33867e8577a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#Reshape our input\n",
    "vgg16 = VGG16(weights='imagenet', \n",
    "              include_top=False, \n",
    "              input_shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "La-p35JEAegx",
    "outputId": "c0199754-654a-48af-9b1a-7b5b3ad2562a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Check to ensure there is no prediction layer\n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "32bIqeFJAepN"
   },
   "outputs": [],
   "source": [
    "#Instantiate a Sequential model\n",
    "vgg16_model = Sequential()\n",
    "\n",
    "#Input Layer\n",
    "vgg16_model.add(vgg16)\n",
    "\n",
    "vgg16_model.add(layers.Flatten())\n",
    "\n",
    "#Add Dense Layer\n",
    "vgg16_model.add(layers.Dense(512, activation='relu'))\n",
    "vgg16_model.add(layers.Dropout(0.2))\n",
    "\n",
    "#Add Dense Layer\n",
    "vgg16_model.add(layers.Dense(64, activation='relu'))\n",
    "vgg16_model.add(layers.Dropout(0.2))\n",
    "\n",
    "#Output Layer\n",
    "vgg16_model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRRHrE9eAel7",
    "outputId": "809bacf9-0b47-495f-8caa-30ffa45e2937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg16 False\n",
      "flatten_1 True\n",
      "dense_3 True\n",
      "dropout_2 True\n",
      "dense_4 True\n",
      "dropout_3 True\n",
      "dense_5 True\n"
     ]
    }
   ],
   "source": [
    "#Freeze our VGG19 Layer\n",
    "vgg16.trainable = False\n",
    "\n",
    "#Sanity check that VGG19 Layer is frozen\n",
    "for layer in vgg16_model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lT7Mk3tsAesA",
    "outputId": "86cc5b06-cba9-4f8b-f884-d21f2e832134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 8, 8, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               16777728  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,525,898\n",
      "Trainable params: 16,811,210\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Compile the model- adam optimizer, categorical_crossentropy loss, and set our metric to accuracy\n",
    "vgg16_model.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRiOyXdAAeu8",
    "outputId": "c0b1ef89-2786-43b1-ebfc-0f43adafc950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "148/148 [==============================] - 70s 461ms/step - loss: 1.4968 - accuracy: 0.4737 - val_loss: 0.7148 - val_accuracy: 0.7675\n",
      "Epoch 2/50\n",
      "148/148 [==============================] - 70s 470ms/step - loss: 0.7753 - accuracy: 0.7271 - val_loss: 0.5783 - val_accuracy: 0.8038\n",
      "Epoch 3/50\n",
      "148/148 [==============================] - 70s 469ms/step - loss: 0.6284 - accuracy: 0.7804 - val_loss: 0.5246 - val_accuracy: 0.8156\n",
      "Epoch 4/50\n",
      "148/148 [==============================] - 70s 472ms/step - loss: 0.5559 - accuracy: 0.8043 - val_loss: 0.5170 - val_accuracy: 0.8160\n",
      "Epoch 5/50\n",
      "148/148 [==============================] - 71s 476ms/step - loss: 0.5159 - accuracy: 0.8263 - val_loss: 0.4605 - val_accuracy: 0.8397\n",
      "Epoch 6/50\n",
      "148/148 [==============================] - 70s 469ms/step - loss: 0.4507 - accuracy: 0.8454 - val_loss: 0.4459 - val_accuracy: 0.8493\n",
      "Epoch 7/50\n",
      "148/148 [==============================] - 70s 474ms/step - loss: 0.4404 - accuracy: 0.8517 - val_loss: 0.4254 - val_accuracy: 0.8597\n",
      "Epoch 8/50\n",
      "148/148 [==============================] - 68s 457ms/step - loss: 0.4074 - accuracy: 0.8603 - val_loss: 0.4751 - val_accuracy: 0.8430\n",
      "Epoch 9/50\n",
      "148/148 [==============================] - 68s 457ms/step - loss: 0.4188 - accuracy: 0.8564 - val_loss: 0.4291 - val_accuracy: 0.8589\n",
      "Epoch 10/50\n",
      "148/148 [==============================] - 68s 457ms/step - loss: 0.3892 - accuracy: 0.8661 - val_loss: 0.4388 - val_accuracy: 0.8475\n",
      "Epoch 11/50\n",
      "148/148 [==============================] - 69s 469ms/step - loss: 0.3533 - accuracy: 0.8798 - val_loss: 0.4027 - val_accuracy: 0.8712\n",
      "Epoch 12/50\n",
      "148/148 [==============================] - 68s 456ms/step - loss: 0.3344 - accuracy: 0.8837 - val_loss: 0.4674 - val_accuracy: 0.8526\n",
      "Epoch 13/50\n",
      "148/148 [==============================] - 68s 456ms/step - loss: 0.3458 - accuracy: 0.8787 - val_loss: 0.4229 - val_accuracy: 0.8641\n",
      "Epoch 14/50\n",
      "148/148 [==============================] - 68s 458ms/step - loss: 0.3318 - accuracy: 0.8854 - val_loss: 0.4151 - val_accuracy: 0.8652\n",
      "Epoch 15/50\n",
      "148/148 [==============================] - 67s 453ms/step - loss: 0.3464 - accuracy: 0.8823 - val_loss: 0.4519 - val_accuracy: 0.8571\n",
      "Epoch 16/50\n",
      "148/148 [==============================] - 69s 468ms/step - loss: 0.2912 - accuracy: 0.9024 - val_loss: 0.4059 - val_accuracy: 0.8749\n",
      "Epoch 17/50\n",
      "148/148 [==============================] - 68s 461ms/step - loss: 0.3001 - accuracy: 0.8986 - val_loss: 0.4241 - val_accuracy: 0.8734\n",
      "Epoch 18/50\n",
      "148/148 [==============================] - 68s 456ms/step - loss: 0.2951 - accuracy: 0.8972 - val_loss: 0.4375 - val_accuracy: 0.8671\n",
      "Epoch 19/50\n",
      "148/148 [==============================] - 67s 455ms/step - loss: 0.2767 - accuracy: 0.9050 - val_loss: 0.4163 - val_accuracy: 0.8734\n",
      "Epoch 20/50\n",
      "148/148 [==============================] - 67s 455ms/step - loss: 0.2947 - accuracy: 0.9009 - val_loss: 0.4462 - val_accuracy: 0.8715\n",
      "Epoch 21/50\n",
      "148/148 [==============================] - 67s 454ms/step - loss: 0.2714 - accuracy: 0.9075 - val_loss: 0.4851 - val_accuracy: 0.8497\n",
      "Epoch 21: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria \n",
    "valcallback = [EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 5), \n",
    "               ModelCheckpoint(filepath='/content/drive/MyDrive/Data/Land_Cover_Classification_Project/vgg16_model.h5', \n",
    "                               monitor='val_accuracy', \n",
    "                               save_best_only=True, \n",
    "                               mode='max')]\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "vgg16_model_history = vgg16_model.fit(vgg16_train_generator, \n",
    "                                  epochs= 50, \n",
    "                                  validation_data = vgg16_val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGM5iQmLAexd",
    "outputId": "77d93789-e4d5-49c5-94b1-253035597f46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 17s 387ms/step - loss: 0.4698 - accuracy: 0.8593\n",
      "Test loss:  0.46979963779449463\n",
      "Test accuracy:  0.8592592477798462\n"
     ]
    }
   ],
   "source": [
    "# Check loss and accuracy on test data\n",
    "test_loss, test_acc = vgg16_model.evaluate(vgg16_test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kh4mYUaAyEEy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4G3UPog9sVu"
   },
   "source": [
    "### Model 16- Transfer Learning: VGG16 with Augmentation and Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WvtP6qc9sbx"
   },
   "source": [
    "Fine Tuning some of the layers in the VGG16 model and using 0.3 Dropout Regualarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_e4TmoJNERye",
    "outputId": "87500d9c-d55e-49ad-e3ff-6572174cb659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18909 images belonging to 10 classes.\n",
      "Found 2701 images belonging to 10 classes.\n",
      "Found 5400 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_folder = '/content/drive/MyDrive/Data/Land_Cover_Classification_Project/data/split/train'\n",
    "test_folder = '/content/drive/MyDrive/Data/Land_Cover_Classification_Project/data/split/test'\n",
    "\n",
    "# Normalize images\n",
    "train_aug16_gen = ImageDataGenerator(rescale=1./255, \n",
    "                                     zoom_range=0.3, \n",
    "                                     rotation_range=50, \n",
    "                                     width_shift_range=0.2, \n",
    "                                     height_shift_range=0.2, \n",
    "                                     shear_range=0.2, \n",
    "                                     horizontal_flip=True, \n",
    "                                     fill_mode='nearest',\n",
    "                                     preprocessing_function = tf.keras.applications.vgg16.preprocess_input,\n",
    "                                     validation_split = 0.125)\n",
    "\n",
    "val_aug16_gen = ImageDataGenerator(rescale=1./255, \n",
    "                               preprocessing_function = tf.keras.applications.vgg16.preprocess_input,\n",
    "                               validation_split = 0.125)\n",
    "\n",
    "test_aug16_gen = ImageDataGenerator(rescale=1./255, \n",
    "                              preprocessing_function = tf.keras.applications.vgg16.preprocess_input)\n",
    "\n",
    "#Import data as 70% Train (10% Validation of orginal data set) and 20% Test\n",
    "aug16_train_generator = train_aug16_gen.flow_from_directory(train_folder,\n",
    "                                                class_mode = 'categorical', \n",
    "                                                subset ='training', \n",
    "                                                batch_size=128,\n",
    "                                                shuffle=True,\n",
    "                                                seed=42)\n",
    "                                               \n",
    "aug16_val_generator= val_aug16_gen.flow_from_directory(train_folder,\n",
    "                                             class_mode= 'categorical',\n",
    "                                             subset = \"validation\",\n",
    "                                             batch_size=128,\n",
    "                                             shuffle=True,\n",
    "                                             seed=42)\n",
    "\n",
    "aug16_test_generator= test_aug16_gen.flow_from_directory(test_folder,\n",
    "                                              class_mode= 'categorical',\n",
    "                                              batch_size=128,\n",
    "                                              shuffle=False,\n",
    "                                              seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rq5nCIKYAe0n",
    "outputId": "11066327-47d4-42bc-f198-c5faa74f27bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#Reshape our input\n",
    "vgg16 = VGG16(weights='imagenet', \n",
    "              include_top=False, \n",
    "              input_shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fs8gJ1eCAe2d"
   },
   "outputs": [],
   "source": [
    "#Instantiate a Sequential model\n",
    "aug_vgg16_model = Sequential()\n",
    "\n",
    "#Input Layer\n",
    "aug_vgg16_model.add(vgg16)\n",
    "\n",
    "aug_vgg16_model.add(layers.Flatten())\n",
    "\n",
    "#Add Dense Layer\n",
    "aug_vgg16_model.add(layers.Dense(512, activation='relu'))\n",
    "aug_vgg16_model.add(layers.Dropout(0.3))\n",
    "\n",
    "#Add Dense Layer\n",
    "aug_vgg16_model.add(layers.Dense(64, activation='relu'))\n",
    "aug_vgg16_model.add(layers.Dropout(0.3))\n",
    "\n",
    "#Output Layer\n",
    "aug_vgg16_model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3ED_y_cAe52",
    "outputId": "fba4759f-6085-47a1-fb39-a178c9330307"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the VGG16 base model:  19\n"
     ]
    }
   ],
   "source": [
    "# View number of layers in the vgg16 base model\n",
    "print(\"Number of layers in the VGG16 base model: \", len(vgg16.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-ywMVPsmAe8a"
   },
   "outputs": [],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 15\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in vgg16.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdVpXKrEAfJN",
    "outputId": "82b7565b-512f-473e-9cf3-1be21b0290b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg16 True\n",
      "flatten True\n",
      "dense True\n",
      "dropout True\n",
      "dense_1 True\n",
      "dropout_1 True\n",
      "dense_2 True\n"
     ]
    }
   ],
   "source": [
    "#Sanity check that VGG19 Layer is frozen\n",
    "for layer in aug_vgg16_model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ozi28YuN-q8k",
    "outputId": "fed291ea-8ad4-4c84-9770-2f3c6b0b1db3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 7,079,424\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SHZnHz6Y-q_u",
    "outputId": "e875ef7d-ffe2-4f72-9eb8-b6826732f9ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 8, 8, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               16777728  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,525,898\n",
      "Trainable params: 23,890,634\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Compile the model- adam optimizer, categorical_crossentropy loss, and set our metric to accuracy\n",
    "aug_vgg16_model.compile(optimizer='adam', \n",
    "                       loss='categorical_crossentropy',  \n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "aug_vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79NHnNuv-rC3",
    "outputId": "6b3a83b0-8360-4af3-f5d7-ac096843d55d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "148/148 [==============================] - 8367s 56s/step - loss: 1.7496 - accuracy: 0.3366 - val_loss: 1.1980 - val_accuracy: 0.5387\n",
      "Epoch 2/50\n",
      "148/148 [==============================] - 285s 2s/step - loss: 1.0871 - accuracy: 0.6081 - val_loss: 1.1515 - val_accuracy: 0.6453\n",
      "Epoch 3/50\n",
      "148/148 [==============================] - 286s 2s/step - loss: 0.8536 - accuracy: 0.6998 - val_loss: 0.9231 - val_accuracy: 0.6716\n",
      "Epoch 4/50\n",
      "148/148 [==============================] - 289s 2s/step - loss: 0.7507 - accuracy: 0.7347 - val_loss: 0.7040 - val_accuracy: 0.7445\n",
      "Epoch 5/50\n",
      "148/148 [==============================] - 286s 2s/step - loss: 0.6526 - accuracy: 0.7799 - val_loss: 0.5437 - val_accuracy: 0.8208\n",
      "Epoch 6/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.5978 - accuracy: 0.7995 - val_loss: 0.5423 - val_accuracy: 0.8160\n",
      "Epoch 7/50\n",
      "148/148 [==============================] - 286s 2s/step - loss: 0.5293 - accuracy: 0.8281 - val_loss: 0.3958 - val_accuracy: 0.8675\n",
      "Epoch 8/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.5013 - accuracy: 0.8392 - val_loss: 0.4993 - val_accuracy: 0.8267\n",
      "Epoch 9/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.4737 - accuracy: 0.8488 - val_loss: 0.5097 - val_accuracy: 0.8538\n",
      "Epoch 10/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.4872 - accuracy: 0.8481 - val_loss: 0.4229 - val_accuracy: 0.8582\n",
      "Epoch 11/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.4271 - accuracy: 0.8622 - val_loss: 0.7218 - val_accuracy: 0.7853\n",
      "Epoch 12/50\n",
      "148/148 [==============================] - 285s 2s/step - loss: 0.4265 - accuracy: 0.8628 - val_loss: 0.4060 - val_accuracy: 0.8726\n",
      "Epoch 13/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.4233 - accuracy: 0.8666 - val_loss: 0.4610 - val_accuracy: 0.8401\n",
      "Epoch 14/50\n",
      "148/148 [==============================] - 285s 2s/step - loss: 0.3896 - accuracy: 0.8767 - val_loss: 0.3028 - val_accuracy: 0.8949\n",
      "Epoch 15/50\n",
      "148/148 [==============================] - 284s 2s/step - loss: 0.4005 - accuracy: 0.8720 - val_loss: 0.3957 - val_accuracy: 0.8812\n",
      "Epoch 16/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.3749 - accuracy: 0.8809 - val_loss: 0.4535 - val_accuracy: 0.8608\n",
      "Epoch 17/50\n",
      "148/148 [==============================] - 286s 2s/step - loss: 0.3541 - accuracy: 0.8879 - val_loss: 0.2991 - val_accuracy: 0.9067\n",
      "Epoch 18/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.3481 - accuracy: 0.8901 - val_loss: 0.3464 - val_accuracy: 0.8852\n",
      "Epoch 19/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.3572 - accuracy: 0.8895 - val_loss: 0.3469 - val_accuracy: 0.8830\n",
      "Epoch 20/50\n",
      "148/148 [==============================] - 282s 2s/step - loss: 0.3553 - accuracy: 0.8887 - val_loss: 0.3928 - val_accuracy: 0.8726\n",
      "Epoch 21/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.3419 - accuracy: 0.8944 - val_loss: 0.3417 - val_accuracy: 0.8926\n",
      "Epoch 22/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.3295 - accuracy: 0.8954 - val_loss: 0.4395 - val_accuracy: 0.8756\n",
      "Epoch 23/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.3301 - accuracy: 0.8965 - val_loss: 0.3028 - val_accuracy: 0.8997\n",
      "Epoch 24/50\n",
      "148/148 [==============================] - 286s 2s/step - loss: 0.3297 - accuracy: 0.8984 - val_loss: 0.2455 - val_accuracy: 0.9148\n",
      "Epoch 25/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.3085 - accuracy: 0.9002 - val_loss: 0.3220 - val_accuracy: 0.8934\n",
      "Epoch 26/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.3220 - accuracy: 0.9007 - val_loss: 0.5104 - val_accuracy: 0.8619\n",
      "Epoch 27/50\n",
      "148/148 [==============================] - 284s 2s/step - loss: 0.3161 - accuracy: 0.9006 - val_loss: 0.3670 - val_accuracy: 0.8874\n",
      "Epoch 28/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.3073 - accuracy: 0.9034 - val_loss: 0.3145 - val_accuracy: 0.8886\n",
      "Epoch 29/50\n",
      "148/148 [==============================] - 286s 2s/step - loss: 0.2956 - accuracy: 0.9067 - val_loss: 0.2675 - val_accuracy: 0.9152\n",
      "Epoch 30/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.2952 - accuracy: 0.9073 - val_loss: 0.2814 - val_accuracy: 0.9041\n",
      "Epoch 31/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.2889 - accuracy: 0.9085 - val_loss: 0.3113 - val_accuracy: 0.9089\n",
      "Epoch 32/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.2909 - accuracy: 0.9099 - val_loss: 0.3269 - val_accuracy: 0.8982\n",
      "Epoch 33/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.2763 - accuracy: 0.9117 - val_loss: 0.3594 - val_accuracy: 0.9026\n",
      "Epoch 34/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.2975 - accuracy: 0.9077 - val_loss: 0.2817 - val_accuracy: 0.9141\n",
      "Epoch 35/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.2722 - accuracy: 0.9147 - val_loss: 0.2786 - val_accuracy: 0.9111\n",
      "Epoch 36/50\n",
      "148/148 [==============================] - 286s 2s/step - loss: 0.2688 - accuracy: 0.9162 - val_loss: 0.2631 - val_accuracy: 0.9171\n",
      "Epoch 37/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.2712 - accuracy: 0.9120 - val_loss: 0.3186 - val_accuracy: 0.9115\n",
      "Epoch 38/50\n",
      "148/148 [==============================] - 285s 2s/step - loss: 0.2603 - accuracy: 0.9189 - val_loss: 0.2681 - val_accuracy: 0.9182\n",
      "Epoch 39/50\n",
      "148/148 [==============================] - 284s 2s/step - loss: 0.2675 - accuracy: 0.9138 - val_loss: 0.3744 - val_accuracy: 0.8908\n",
      "Epoch 40/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.2537 - accuracy: 0.9196 - val_loss: 0.3276 - val_accuracy: 0.9045\n",
      "Epoch 41/50\n",
      "148/148 [==============================] - 286s 2s/step - loss: 0.2559 - accuracy: 0.9182 - val_loss: 0.2479 - val_accuracy: 0.9241\n",
      "Epoch 42/50\n",
      "148/148 [==============================] - 284s 2s/step - loss: 0.2581 - accuracy: 0.9198 - val_loss: 0.2709 - val_accuracy: 0.9082\n",
      "Epoch 43/50\n",
      "148/148 [==============================] - 285s 2s/step - loss: 0.2613 - accuracy: 0.9167 - val_loss: 0.2894 - val_accuracy: 0.9119\n",
      "Epoch 44/50\n",
      "148/148 [==============================] - 288s 2s/step - loss: 0.2523 - accuracy: 0.9196 - val_loss: 0.2451 - val_accuracy: 0.9260\n",
      "Epoch 45/50\n",
      "148/148 [==============================] - 284s 2s/step - loss: 0.2526 - accuracy: 0.9188 - val_loss: 0.3035 - val_accuracy: 0.9023\n",
      "Epoch 46/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.2704 - accuracy: 0.9167 - val_loss: 0.5039 - val_accuracy: 0.8563\n",
      "Epoch 47/50\n",
      "148/148 [==============================] - 286s 2s/step - loss: 0.2524 - accuracy: 0.9190 - val_loss: 0.2450 - val_accuracy: 0.9282\n",
      "Epoch 48/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.2429 - accuracy: 0.9211 - val_loss: 0.2900 - val_accuracy: 0.9074\n",
      "Epoch 49/50\n",
      "148/148 [==============================] - 285s 2s/step - loss: 0.2966 - accuracy: 0.9147 - val_loss: 0.2834 - val_accuracy: 0.9193\n",
      "Epoch 50/50\n",
      "148/148 [==============================] - 283s 2s/step - loss: 0.2471 - accuracy: 0.9202 - val_loss: 0.2905 - val_accuracy: 0.9111\n"
     ]
    }
   ],
   "source": [
    "# Define Stopping Criteria- changed patience to 10\n",
    "valcallback = [EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience = 10), \n",
    "               ModelCheckpoint(filepath='/content/drive/MyDrive/Data/Land_Cover_Classification_Project/aug_vgg16_model.h5', \n",
    "                               monitor='val_accuracy', \n",
    "                               save_best_only=True, \n",
    "                               mode='max')]\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "aug_vgg16_model_history = aug_vgg16_model.fit(aug16_train_generator, \n",
    "                                  epochs= 50, \n",
    "                                  validation_data = aug16_val_generator, \n",
    "                                  callbacks= valcallback, \n",
    "                                  batch_size=128, \n",
    "                                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XKXe1qgi-rFw",
    "outputId": "3a8615fe-ff4e-4a0e-f665-f79203fbe891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 2138s 51s/step - loss: 0.2987 - accuracy: 0.9146\n",
      "Test loss:  0.2986944913864136\n",
      "Test accuracy:  0.9146296381950378\n"
     ]
    }
   ],
   "source": [
    "# Check loss and accuracy on test data\n",
    "test_loss, test_acc = aug_vgg16_model.evaluate(aug16_test_generator, verbose = 1)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ldoDoVg_Wkn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lImGI7BxVzs"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKM1Gv_MxWC5"
   },
   "source": [
    "Compared to my Baseline Model's performance of 74.1% Test accuracy, my final model was Model 16 with a 91.4% Test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "I3NL1ACxUXUU"
   },
   "outputs": [],
   "source": [
    "#Plot training and validation results of a model\n",
    "def visualize_training_results(results):\n",
    "    history = results.history\n",
    "    plt.figure()\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.plot(history['loss'])\n",
    "    plt.legend(['val_loss', 'loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.legend(['val_accuracy', 'accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "pThOiZ0WVSyL",
    "outputId": "29d99782-6106-4800-a39a-66b68e358839"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d4e247af696e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Plot the traning/validation results of our baseline model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvisualize_training_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'baseline_history' is not defined"
     ]
    }
   ],
   "source": [
    "#Plot the traning/validation results of our baseline model\n",
    "visualize_training_results(baseline_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "HZtImPsXUXau",
    "outputId": "72bc2d9a-ce44-43f2-be9e-9b8e2749b0eb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the traning/validation results of our best model- Model 16\n",
    "visualize_training_results(aug_vgg16_model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ca8sgZgAxibZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PivHPGN8xjgg"
   },
   "source": [
    "Let's look at our predictions for our final model (Model 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Gru7RuIeUXmd"
   },
   "outputs": [],
   "source": [
    "final_model = tf.keras.models.load_model('aug_vgg16_model.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VCACzKR5yCS9"
   },
   "outputs": [],
   "source": [
    "#Split into X_test(images) and y_test (labels)\n",
    "# test_images, test_labels = next(aug16_test_generator)\n",
    "test_images, test_labels = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "zHyBxpjxyCeW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 9 9 9]\n"
     ]
    }
   ],
   "source": [
    "true_classes = test_generator.classes\n",
    "print(true_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n"
     ]
    }
   ],
   "source": [
    "class_labels = list(test_generator.class_indices.keys())   \n",
    "\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jcJb_X3aAzF6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.91743657e-01, 1.57013278e-14, 1.01515587e-08, ...,\n",
       "        2.01686337e-14, 1.92119703e-02, 1.69866584e-12],\n",
       "       [9.99871850e-01, 7.59539107e-19, 8.85351903e-10, ...,\n",
       "        1.72882623e-27, 1.00013014e-04, 2.82931312e-13],\n",
       "       [9.99479949e-01, 9.56265895e-20, 6.29354208e-11, ...,\n",
       "        1.04330318e-29, 5.19015302e-04, 7.28698907e-11],\n",
       "       ...,\n",
       "       [9.78022218e-01, 2.67193870e-16, 3.88125115e-10, ...,\n",
       "        1.73888310e-23, 1.84616428e-02, 8.12065437e-09],\n",
       "       [8.75034750e-01, 4.42954094e-12, 1.52073949e-06, ...,\n",
       "        1.04100273e-14, 2.88412906e-02, 4.82540230e-08],\n",
       "       [7.53202796e-01, 5.40165615e-07, 6.39617210e-04, ...,\n",
       "        4.28057660e-08, 9.45565775e-02, 1.40817734e-04]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Probability for each class\n",
    "y_proba = final_model.predict(test_images)\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5Dz6hXb7x0Hs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 0, 0, 3, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0,\n",
       "       3, 0, 8, 0, 3, 0, 0, 3, 0, 0, 0, 0, 3, 0, 3, 0, 3, 0, 0, 0, 0, 0,\n",
       "       0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 8, 3, 0, 0, 8, 0, 0, 3, 0, 0, 0, 0,\n",
       "       0, 3, 8, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 8, 3, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 6, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## argmax axis = -1 gets the column index of maximum probability for each row.\n",
    "## column index corresponds to digit classes (numbers 0 -9)\n",
    "predicted = np.argmax(y_proba, axis=-1)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels.argmax(axis=-1), predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)#, display_labels=labels)\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n",
    "\n",
    "# multilabel_confusion_matrix(test_labels.argmax(axis=-1), predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f642047ea312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_of_test_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m43\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mnum_of_test_samples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Predictions on entire train data\n",
    "batch_size = 128\n",
    "num_of_test_samples = 43\n",
    "predictions = final_model.predict(test_generator,  num_of_test_samples // batch_size+1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5400, 128]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-637b7ad8e093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \"\"\"\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5400, 128]"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "class_labels = list(test_generator.class_indices.keys())   \n",
    "\n",
    "print(class_labels)\n",
    "\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n",
    "\n",
    "report = classification_report(true_classes, y_pred, target_names=class_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "LHBRURk9x0rl"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-322d201f5c0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##View confusion matrix of test predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcm_digits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m disp = ConfusionMatrixDisplay(\n\u001b[1;32m      4\u001b[0m     confusion_matrix=cm_digits)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \"\"\"\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[1;32m     91\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
     ]
    }
   ],
   "source": [
    "##View confusion matrix of test predictions\n",
    "cm_digits = confusion_matrix(test_labels, predicted)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm_digits)\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PVm8RBw6UXt7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OslcehyuUX6F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DyPJJgqlUYAM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNIjihGcUYML"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2iIoxXrAzGb"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KptBbdkcAzGb"
   },
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eisyP48jAzGb"
   },
   "source": [
    "- Use this land cover classifier tool on images of the same land area over time.\n",
    "- Focus deforestation prevention efforts on known wildlife corridor areas where an imageâ€™s class has changed over time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OI_-biIrAzGc"
   },
   "source": [
    "### Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pf1nBjxCAzGc"
   },
   "source": [
    "Create object detection to help classify multiple areas of land cover within an image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32ZvJbltAzGc"
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOPDOPMEAzGc"
   },
   "source": [
    "[1] Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification. Patrick Helber, Benjamin Bischke, Andreas Dengel, Damian Borth. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26AxyM_xAzGc"
   },
   "source": [
    "[2] Introducing EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification. Patrick Helber, Benjamin Bischke, Andreas Dengel. 2018 IEEE International Geoscience and Remote Sensing Symposium, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEuxSFHMAzGc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
